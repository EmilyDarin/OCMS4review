---
output: 
    html_document:
        css: styles.css
runtime: shiny
---

# Evaluation of OC MS4 monitoring program, mass emissions {.tabset}

```{r setup, message = F, warning = F, results = 'hide', echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, echo = F, fig.path = 'figs/', dev.args = list(family = 'serif'))

library(tidyverse)
library(sf)
library(mapview)
library(lubridate)
library(leaflet)
library(leafsync)
library(viridisLite)
library(lubridate)
library(gridExtra)
library(stargazer)
library(EnvStats)
library(shiny)
library(kableExtra)
library(mgcv)
library(metR)
library(vegan)
library(ggord)
library(patchwork)
library(ggrepel)
library(ggExtra)
library(plotly)
library(matrixStats)
library(scales)
library(reactable)

mptyps <- c("CartoDB.Positron", "CartoDB.DarkMatter", "OpenStreetMap", "Esri.WorldImagery", "OpenTopoMap")

mapviewOptions(leafletHeight = 300)

prj <- 4326 # wgs84

source('R/funcs.R')

##
# ggplot themes

thm1 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    strip.text = element_text(hjust = 0),
    axis.title.x = element_blank(), 
    legend.title = element_blank(), 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm2 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm3 <- theme_bw(base_size = 12) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

pbase <- theme_bw(base_family = 'serif') +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10), 
    axis.text.y = element_text(size = 10),
    legend.position = 'top',
    legend.direction = 'horizontal',
    # plot.margin = unit(c(4,4,0,0), "lines"),
    strip.background = element_blank(), 
    strip.text.y = element_text(angle = 0, hjust = 0, vjust = 0.5), 
    panel.background = element_rect(fill = 'black')
  ) 

data(medat)
data(thrsdat)
data(pows)
data(thrs)
data(opteff)

reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

# constituents
metals <- c("Ag", "As", "Cd", "Cr", "Cu", "Fe", "Hg", "Ni", "Pb", "Se", 
            "Zn")
organs <- c("Azinphos methyl (Guthion)", "Bolstar", "Chlorpyrifos", "Coumaphos", 
            "Demeton-o", "Demeton-s", "Diazinon", "Dichlorvos", "Dimethoate", 
            "Disulfoton", "Ethoprop", "Ethyl Parathion", "Fensulfothion", 
            "Fenthion", "GLYP", "Malathion", "Merphos", "Mevinphos", 
            "Parathion-methyl", "Phorate", "Ronnel", "Tetrachlorovinphos", 
            "Tokuthion", "Trichloronate")
nutrs <- c('Ammonia', 'Nitrate, Nitrite', 'Total Kjeldahl Nitrogen', 'Orthophosphate', 'Total Phosphorus')
```

```{r reactives}
# inventory table
invtab <- reactive({
  
  # input
  consel1 <- input$consel1
  tabtyp <- input$tabtyp


  # filter by parameters
  tofilt <- eval(parse(text = consel1))
  sums <- medat %>% 
    filter(Parameter %in% tofilt)
  
  if(tabtyp == 'Number of observations'){
    
    sums <- sums %>% 
      dplyr::count(Parameter, StationCode) %>% 
      bind_rows(group_by(., Parameter) %>%
                summarise(n=sum(n)) %>%
                mutate(StationCode='Total')) %>%
      bind_rows(group_by(., StationCode) %>%
                summarise(n=sum(n)) %>%
                mutate(Parameter='Total')) %>%
      spread(Parameter, n, fill=0) %>% 
      select_at(c('StationCode', tofilt, 'Total'))
  
    alltot <- sums %>% 
      filter(StationCode != 'Total')
    coltot <- sums %>% 
      filter(StationCode == 'Total')
    
    totab <- bind_rows(alltot, coltot)
    
    cap <- 'Number of observations at each site'
  
  }
        
  if(tabtyp == 'Variance'){
    
    totab <- sums %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(vr = round(var(Result, na.rm = T), 2)) %>% 
      spread(Parameter, vr, fill = NA)
    
    cap <- 'Variance at each site'
    
  }
  
  if(tabtyp == 'Median absolute deviation'){
    
    totab <- sums %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(md = round(mad(Result, na.rm = T), 2)) %>% 
      spread(Parameter, md, fill = NA)
    
    cap <- 'Median absolute deviation at each site'
    
  }
  
  HTML(knitr::kable(totab, format = 'html', caption = cap) %>% 
      kable_styling(full_width = T, font_size = 14))  
    
})

# selected station, parameter data
stapardat <- reactive({
  
  # inputs
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel

  req(varsel)
  req(stasel)
  
  out <- medat %>% 
    filter(StationCode %in% stasel) %>% 
    filter(Parameter %in% varsel) %>% 
    filter(Type %in% smpsel) %>% 
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection', 
        T ~ 'within range'
      ),
      Detection = factor(Detection, levels = c('below detection', 'within range')),
      Year = year(Date), 
      Month = month(Date, label = T)
    ) 

  validate(
    need(nrow(out) > 0, 'No data in selection')
  )    
  
  return(out)
  
})

# first observed plot
obsp1 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)
  
  p <- ggplot(toplo, aes(x = Date, y = Result)) + 
    geom_line() + 
    geom_point(aes(colour = Detection)) + 
    thm1 + 
    # scale_y_log10() + 
    scale_colour_manual(values = c('tomato1', 'black'), drop = F) + 
    labs(
      subtitle = stasel, 
      title = ttl, 
      y = 'Concentration (mg/L)'
    )
  
  return(p)
  
})

# second observed plot
obsp2 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) + 
    geom_boxplot() + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      subtitle = stasel,
      title = paste(ttl, 'by year'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# third observed plot
obsp3 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) + 
    geom_boxplot() + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      subtitle = stasel, 
      title = paste(ttl, 'by month'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# trend data
trnddat <- reactive({
  
  # input
  stapardat <- stapardat()
  
  out <- try({stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    ungroup %>%
    mutate(
      avg = round(avg, 2),
      Parameter = paste0(Parameter, ' (', avg, ')')
    )
  })
  
  return(out)
  
})

# first trend plot
trndp1 <- reactive({
  
  # input
  trnddat <- trnddat()
  stasel <- input$stasel
  
  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )
  
  subttl <- paste0(stasel, ', average in parentheses on y-axis')
  
  p <- ggplot(trnddat, aes(x = Year, y = dev, fill = dev)) +
    geom_bar(stat = 'identity', colour = 'grey') +
    scale_fill_gradient2('Deviations from average (+/-)', low = 'tomato1', mid = 'grey90', high = 'lightgreen', midpoint = 0) +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(axis.title.y = element_blank()) +
    geom_smooth(method = 'lm', se = F, linetype = 'dashed', color = 'black') +
    # scale_y_log10() +
    # scale_y_continuous('Density (fish/100ft)') +
    geom_hline(aes(yintercept = 0)) +
    labs(
      title = 'Deviation from annual averages by constituent (mg/L)',
      subtitle = subttl
    ) + 
    guides(fill = guide_colourbar(barwidth = 15, barheight = 0.5))
  
  return(p)
    
})

# first trend table
trndtab1 <- reactive({
  
  # input
  trnddat <- trnddat()
  
  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )
  
  mods <- trnddat %>%
    group_by(Parameter) %>%
    nest %>%
    mutate(
      mod = purrr::map(data, function(x) lm(dev ~ Year, x))
    ) %>%
    ungroup %>%
    mutate(
      Parameter = gsub('\\s\\(.*\\)$', '', Parameter)
    )
  
  out <- stargazer(mods$mod, type = 'html',
            covariate.labels = c('Year', 'Intercept'),
            column.labels = mods$Parameter,
            omit.stat = c('adj.rsq', 'ser'),
            column.sep.width = '10pt',
            dep.var.labels.include = F,
            digits = 2
            ) %>% 
    HTML()
  
  return(out)

})

# second trend plot
trndp2 <- reactive({
  
  # input
  stapardat <- stapardat()
  stasel <- input$stasel
  varsel <- input$varsel
  
  win <- 12
  toplo <- stapardat %>%
    select(Date, Parameter, Result) %>%
    mutate(Date = floor_date(Date, unit = 'month')) %>%
    group_by(Date, Parameter) %>%
    summarise(Result = mean(Result, na.rm = T)) %>%
    # group_by(Parameter) %>%
    arrange(Parameter, Date) %>%
    group_by(Parameter) %>%
    mutate(
      avg = stats::filter(Result, rep(1, win)/win, sides = 1, method = 'convolution')
    ) %>%
    ungroup %>%
    mutate(
      dev = Result - avg
    )

  p1 <- ggplot(toplo, aes(x = Date, y = Result)) +
    geom_line() +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(axis.title.y = element_blank()) +
    # scale_y_log10() +
    labs(
      title = paste0('Observed ', varsel),
      subtitle = stasel,
      ylab = 'Concentration (mg/L)'
    )

  p2 <- ggplot(toplo, aes(x = Date, y = avg)) +
    geom_segment(aes(x = Date, xend = Date, yend = avg, y = avg + dev, colour = dev), size = 0.8) +
    geom_line(colour = 'black') +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(legend.position = 'right') +
    # scale_y_log10() +
    scale_colour_gradient2('Devation from average (+/-)', low = 'tomato1', mid = 'grey90', high = 'lightgreen', midpoint = 0) +
    labs(
      title = 'Deviations from annual average',
      subtitle = stasel,
      ylab = NULL
    )

  grid.arrange(
    arrangeGrob(p1, p2, ncol = 2, widths = c(0.8,1))
  )
  
})

# second trends table
trndtab2 <- reactive({
  
  # input
  stapardat <- stapardat()
  
  totabs1kn <- stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){
  
        knout <- kendallTrendTest(dev ~ Year, x)
        outest <- round(knout$estimate, 2)
        outpval <- p_ast(knout$p.value)
        nval <- nrow(na.omit(x))
        out <- c(n = nval, outest, pval = outpval) %>%
          data.frame %>%
          t %>%
          data.frame %>%
          select(-intercept)
        return(out)
  
      })
  
    ) %>%
    select(-data) %>%
    unnest(res)

  out <- HTML(knitr::kable(totabs1kn, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))
  
  return(out)
  
})

# power analysis data
powdat <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel
  
  req(varsel)
  req(stasel)

  out <- medat %>%
    filter(StationCode %in% stasel) %>%
    filter(Parameter %in% varsel) %>%
    filter(Type %in% smpsel) %>% 
    mutate(
      Year = year(Date),
      Season = yday(Date),
      dectime = decimal_date(Date)
    )

  return(out)
  
})

# first power analysis plot
powplo1 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  powdat <- powdat()
  
  p <- ggplot(powdat, aes(x = Date, y = Result)) +
    geom_line() +
    thm2 +
    scale_y_log10() +
    labs(
      title = 'Observed time series',
      subtitle = stasel,
      xlab = NULL,
      y = paste0(varsel, ' (mg/L)')
    )
  
  return(p)
  
})

# second power plot
powplo2 <- reactive({
  
  # input
  powdat <- powdat()
  stasel <- input$stasel
  varsel <- input$varsel
  
  scns <- crossing(
    chg = seq(0.3, 1, length = 2),
    eff = seq(0.3, 1, length = 2)
    ) %>%
    group_by(chg, eff) %>%
    mutate(
      simdat = purrr::pmap(list(chg, eff), ~simvals(powdat, chg, eff, sims = 20)),
      sigs = purrr::map(simdat, function(x){
  
        x <- x %>%
          group_by(sims) %>%
          nest %>%
          mutate(
            pval = purrr::map(data, function(x){
  
              mod <- lm(simrand ~ dectime, data = x) %>% summary %>% .$fstatistic
              pf(mod[1], mod[2], mod[3], lower.tail = F)
  
            }),
            sig = case_when(
              pval < 0.05 ~ 'sig',
              pval >= 0.05 ~ 'nonsig'
            )
          ) %>%
          ungroup %>%
          select(sims, sig)
  
        return(x)
  
      })
    )
  
  simdat <- scns %>%
    select(-sigs) %>%
    unnest(simdat)
  
  sigs <- scns %>%
    select(-simdat) %>%
    unnest(sigs)
  
  toplo <- simdat %>%
    left_join(sigs, by = c('chg', 'eff', 'sims')) %>%
    group_by(chg, eff) %>%
    nest %>%
    mutate(
      pow = purrr::map(data, powfun)
    ) %>%
    unnest(c(data, pow)) %>%
    ungroup %>%
    mutate(
      chg = paste('change', chg),
      eff = paste('effort', eff),
      pow = paste('power', pow),
      sig = case_when(
        sig == 'nonsig' ~ 'Non-significant',
        sig == 'sig' ~ 'Significant'
      )
    ) %>%
    unite('grp', chg, eff, pow, sep = ', ')
  
  p <- ggplot(toplo, aes(x = Date, y = exp(simrand), group = sims, col = sig)) +
    geom_point(size = 0.2) +
    geom_line(alpha = 0.2) +
    facet_wrap(~ grp, ncol = 2) +
    thm2 +
    scale_y_log10() +
    scale_colour_manual('', values = c('black', 'tomato1')) +
    labs(
      title = 'Observed time series (mg/L)',
      subtitle = paste0(stasel, ', twenty simulations per scenario'),
      y = paste0('log-simulated ', varsel, ' (mg/L)'),
      x = NULL
    )
  
  return(p)
  
})

# third power plot
powplo3 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel
  
  toplo <- pows %>% 
    filter(sta %in% stasel) %>% 
    filter(par %in% varsel) %>% 
    filter(wxt %in% smpsel)
  
  p <- ggplot(toplo, aes(x = eff, y = chg, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    # scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Magnitude of trend change (%) of ', varsel),
      title = paste0('Power estimates for ', stasel),
      subtitle = 'Lines show power for varying sample effort and trend magnitude',
      x = 'Relative sample effort'
    )
  
  p
  
})

# fourth power plot
powplo4 <- reactive({
  
  # inputs
  powdat <- powdat()
  stasel <- input$stasel
  varsel <- input$varsel
  
  scns <- crossing(
    thr = seq(1, 10, length = 2),
    eff = seq(0.1, 1, length = 2)) %>%
    group_by(thr, eff) %>%
    mutate(
      simdat = purrr::map(eff, ~thrvals(powdat, eff, sims = 20))
    )
  
  toplo <- scns %>%
    unnest(simdat) %>%
    ungroup %>%
    mutate(
      thr = paste('exceedance', thr),
      eff = paste('effort', eff)
    ) %>%
    unite('grp', thr, eff, sep = ', ', remove = F) %>%
    mutate(
      thr = gsub('^exceedance\\s', '', thr) %>% as.numeric,
      val = case_when(
        exp(simrand) > thr ~ 'Value above',
        exp(simrand) <= thr ~'Value below'
      )
    )
  
  p <- ggplot(toplo, aes(x = Date, y = exp(simrand), group = sims)) +
    geom_line(alpha = 0.2) +
    geom_point(size = 0.5, aes(shape = val, col = val)) +
    geom_hline(aes(yintercept = thr), linetype = 'dashed') +
    facet_wrap(~ grp, nrow = 2) +
    thm2 +
    scale_y_log10() +
    scale_colour_manual(NULL, values = c('tomato1', 'black')) +
    scale_shape_manual(NULL, values = c(24, 25)) +
    labs(
      title = 'Observed time series (mg/L)',
      subtitle = paste0(stasel, ', twenty simulations per scenario'),
      y = paste0('log-simulated ', varsel, ' (mg/L)'),
      x = NULL
    )
  
  p
  
})

# fifth power plot
powplo5 <- reactive({
  
  # inputs
  powdat <- powdat()
  stasel <- input$stasel
  varsel <- input$varsel
  
  scns <- crossing(
    thr = seq(1, 10, length = 2),
    eff = seq(0.1, 1, length = 2)) %>%
    group_by(thr, eff) %>%
    mutate(
      simdat = purrr::map(eff, ~thrvals(powdat, eff, sims = 20))
    )
  
  toplo <- scns %>%
    mutate(
      yrspow = purrr::pmap(list(thr, simdat), function(thr, simdat) {
  
        out <- simdat %>%
          mutate(simrand = exp(simrand)) %>%
          group_by(Year) %>%
          summarise(
            aveval = mean(simrand),
            minval = t.test(simrand)$conf.int[1],
            maxval = t.test(simrand)$conf.int[2]
          ) %>%
          mutate(sig = case_when(
            maxval > thr ~ 'detected',
            maxval < thr ~ 'not detected'
            )
          )
  
        return(out)
  
      })
    ) %>%
    unnest(yrspow) %>%
    ungroup %>%
    mutate(
      thr = paste('exceedance', thr),
      eff = paste('effort', eff)
    ) %>%
    unite('grp', thr, eff, sep = ', ', remove = F) %>%
    mutate(thr = gsub('^exceedance\\s', '', thr) %>%  as.numeric)

  p <- ggplot(toplo, aes(x = factor(Year), y = aveval)) +
    geom_bar(stat = 'identity', aes(fill = sig)) +
    geom_errorbar(aes(ymin = minval, ymax = maxval, color = sig), width = 0) +
    geom_hline(aes(yintercept = thr), linetype = 'dashed') +
    scale_colour_manual(NULL, values = c('tomato1', 'black')) +
    scale_fill_manual(NULL, values = c('tomato1', 'black')) +
    facet_wrap(~ grp, nrow = 2) +
    thm2 +
    labs(
      title = 'Ability to detect exceedance by year',
      subtitle = paste0(stasel, ', twenty simulations per scenario'),
      y = paste0(varsel, ' concentration (mg/L)'),
      x = NULL
    )
  
  return(p)
  
})

# sixth power plot
powplo6 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  
  toplo <- thrs %>% 
    filter(StationCode %in% stasel) %>% 
    filter(Parameter %in% varsel) 
  
  p <- ggplot(toplo, aes(x = effs, y = vals, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Concentration of ', varsel),
      title = paste0('Power estimates for ', stasel),
      subtitle = 'Lines show the likelihood that the true mean for the sample is above the threshold',
      x = 'Relative sample effort'
    )

  p
  
})

# comparison of time series for stations
stapardat2 <- reactive({
  
  # inputs
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2

  req(varsel2)
  
  out <- medat %>% 
    filter(StationCode %in% c(stasel2, stasel3)) %>% 
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection', 
        T ~ 'within range'
      ),
      Year = year(Date), 
      Month = month(Date, label = T), 
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    ) %>%
    filter(Parameter %in% varsel2)
    
  return(out)
  
})

# fourth observed plot
obsp4 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)
  
  p <- ggplot(toplo, aes(x = Date, y = Result)) + 
    geom_line() + 
    geom_point(aes(colour = Detection)) + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 + 
    # scale_y_log10() + 
    scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = ttl, 
      y = 'Concentration (mg/L)'
    )
  
  return(p)
  
})

# fifth observed plot
obsp5 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) + 
    geom_boxplot() + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = paste(ttl, 'by year'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# sixth observed plot
obsp6 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) + 
    geom_boxplot() + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = paste(ttl, 'by month'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# dissimilarity data
disdat <- reactive({
  
  # input
  varsel2 <- input$varsel2
  
  req(varsel2)

  dissim <- meprp %>% 
    filter(Parameter %in% varsel2) %>% 
    select(-Watershed, -Parameter) %>% 
    spread(StationCode, Result) %>% 
    column_to_rownames('Date') %>% 
    decostand(method = 'log', na.rm = T) %>% 
    decostand(method= 'standardize', na.rm = T) %>%
    rownames_to_column('Date') %>% 
    gather('StationCode', 'Result', -Date) %>% 
    spread(Date, Result) %>% 
    column_to_rownames('StationCode') %>% 
    vegdist(method = 'euclidean', na.rm = T) %>%
    as.matrix %>%
    as.data.frame %>%
    rownames_to_column('StationCode') %>%
    gather('StationCode2', 'dist', -StationCode) %>%
    left_join(siteshd, by = 'StationCode') %>%
    arrange(Watershed, dist) %>%
    mutate(
      Watershed = factor(Watershed, levels = unique(Watershed)),
      dist = ifelse(StationCode == StationCode2, NA, dist)
    )
  
  return(dissim)

})

# dissimilarity data, all constituents
discondat <- reactive({
   
  # input
  consel3 <- input$consel3
  
  if(consel3 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel3))
           
  dissim <- meprp %>% 
    filter(Parameter %in% sels) %>% 
    select(-Watershed) %>% 
    group_by(Parameter) %>% 
    nest() %>% 
    mutate(
      dis = purrr::map(data, function(data){
        
        out <- data %>% 
          spread(StationCode, Result) %>% 
          column_to_rownames('Date') %>% 
          decostand(method = 'log', na.rm = T) %>% 
          decostand(method= 'standardize', na.rm = T) %>%
          rownames_to_column('Date') %>% 
          gather('StationCode', 'Result', -Date) %>% 
          spread(Date, Result) %>% 
          column_to_rownames('StationCode') %>% 
          vegdist(method = 'euclidean', na.rm = T) %>%
          as.matrix %>%
          as.data.frame %>%
          rownames_to_column('StationCode') %>%
          gather('StationCode2', 'dist', -StationCode) %>%
          left_join(siteshd, by = 'StationCode') %>%
          arrange(Watershed, dist) %>%
          mutate(
            Watershed = factor(Watershed, levels = unique(Watershed)),
            dist = ifelse(StationCode == StationCode2, NA, dist)
          )
        
        return(out)
        
      })
    ) %>% 
    select(-data) %>% 
    unnest(dis) %>% 
    na.omit %>% 
    group_by(Parameter, StationCode) %>% 
    summarise(dist = mean(dist, na.rm = T)) %>% 
    group_by(StationCode) %>% 
    summarise(dist = mean(dist, na.rm = T))
    
  return(dissim)
  
})

# select unique stations
unisel <- reactive({
  
  # input
  disdat <- disdat()
  unithr <- input$unithr

  req(unithr)
   
  totab <- disdat %>% 
    filter(!is.na(dist)) %>% 
    group_by(StationCode) %>% 
    summarise(dist = mean(dist, na.rm = T)) %>% 
    filter(dist > unithr) %>% 
    arrange(dist) %>% 
    rename(`Avg. dissimilarity` = dist)

  cap <- paste0('Selected "unique" stations using average dissimilarity threshold of ', unithr)
  
  HTML(knitr::kable(totab, format = 'html', caption = cap, digits = 2) %>% 
    kable_styling(full_width = T, font_size = 14))  
    
})

# select unique stations, average across constituents
unisel2 <- reactive({
  
  # input
  discondat <- discondat()
  unithr2 <- input$unithr2

  req(unithr2)
   
  totab <- discondat %>% 
    filter(dist > unithr2) %>% 
    arrange(dist) %>% 
    rename(`Avg. dissimilarity` = dist)

  cap <- paste0('Selected "unique" stations using average dissimilarity threshold of ', unithr2, ', values are averages across constituents.')
  
  HTML(knitr::kable(totab, format = 'html', caption = cap, digits = 2) %>% 
    kable_styling(full_width = T, font_size = 14))  
    
})

# multivariate comparison plots
mulplo <- reactive({
  
  # input
  disdat <- disdat()
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2
  consel3 <- input$consel3
  
  req(varsel2)
  
  ##
  # PCA
         
  if(consel3 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel3))
           
  toord <- meprp %>% 
    filter(Parameter %in% !!sels) %>% 
    spread(Parameter, Result) %>% 
    na.omit %>%
    unite('rwnm', StationCode, Date) %>% 
    column_to_rownames('rwnm')
  wshd <- toord$Watershed
  toord <- toord %>% 
    select(-Watershed) %>% 
    decostand(method = 'log', na.rm = T) %>% 
    decostand(method= 'standardize', na.rm = T) %>% 
    select(which(!is.na(apply(., 2, var))))

  ord <- toord %>% 
    prcomp(scale. = T, center = T)

  # station subset
  vals <- ord$x %>% 
    as.data.frame %>% 
    rownames_to_column() %>% 
    mutate(StationCode = gsub('^(.*)\\_.*$', '\\1', rowname)) %>% 
    filter(StationCode %in% c(stasel2, stasel3)) %>% 
    rename(
      one = PC1, 
      two = PC2
    ) %>% 
    mutate(
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    )

  p1 <- ggord(ord, size = 1, grp_in = wshd, alpha = 0.4, vec_ext = 5, coord_fix = F) + 
    scale_fill_viridis_d(guide_legend(ncol = 1)) + 
    geom_point(data = vals, aes(alpha = StationCode), size = 3) +
    scale_alpha_manual(values = c(0.2, 0.8)) + 
    theme(
      legend.position = 'top',
      legend.title = element_blank(),
      legend.box = 'vertical'
      )
  
  ##
  # dissimilarity data and plots
  outplo <- disdat %>% 
    filter(StationCode %in% stasel2) %>% 
    filter(StationCode2 %in% stasel3)
  
  # dissimilarity ranges
  disrng <- range(disdat$dist, na.rm = T)
  
  dismid <- disrng[1] + (disrng[2] - disrng[1]) / 2
  subttl <- paste0("Dissimilarity between ", stasel2, " and ", stasel3, " ", round(outplo$dist, 1))
  
  p2 <- ggplot(disdat) +
    geom_tile(aes(x = StationCode, y = StationCode2, fill = dist), colour = 'black') +
    geom_tile(data = outplo, aes(x = StationCode, y = StationCode2), fill = NA, colour = 'black', size = 2) +
    scale_x_discrete('', expand = c(0, 0)) +
    scale_y_discrete('', expand = c(0, 0)) +
    scale_fill_gradient2('Dissimilarity between stations', low = 'lightblue', mid = 'white', high = 'tomato1', midpoint = dismid, limits = disrng) +
    guides(fill = guide_colourbar(barheight = 0.5, barwidth = 10, label.theme = element_text(size = 11, angle = 0))) +
    labs(
      title = varsel2, 
      subtitle = subttl
    ) +
    pbase

  p1 + p2 + plot_layout(ncol = 2)
      
})

# treshold value for consituent
varthr <- reactive({
  
  # input
  varsel <- input$varsel
  
  out <- thrsdat %>% 
    filter(Parameter %in% varsel) %>% 
    pull(Threshold)
  
  return(out)
  
})

# optimal sample effort data
optdat <- reactive({
  
  # input
  varthr <- varthr()
  varsel <- input$varsel
  powsel <- input$powsel
  smpsel <- input$smpsel
  shdsel <- input$shdsel
  
  if(shdsel == 'all')
    shdsel <- unique(pows$Watershed)
  
  dat <- pows %>% 
    filter(par %in% varsel) %>% 
    filter(wxt %in% smpsel) %>% 
    filter(Watershed %in% shdsel)

  # get median values of constituent for each station
  meddat <- medat %>% 
    filter(Parameter %in% varsel) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    rename(sta = StationCode)
  
  # use threshold if available
  if(length(varthr) != 0)
    meddat <- meddat %>% 
      mutate(
        thrdif = abs(medval - varthr),
        reldif = (thrdif / varthr)
      )
  
  if(length(varthr) == 0)
    meddat <- meddat %>% 
      mutate(
        thrdif = NaN,
        reldif = NaN
      )

  opts <- dat %>% 
    group_by(sta) %>% 
    nest %>% 
    mutate(
      opt = purrr::map(data, getopt, pow = powsel)
    ) %>% 
    dplyr::select(-data) %>% 
    unnest(opt) %>% 
    dplyr::select(sta, eff, chg) %>% 
    na.omit %>% 
    ungroup %>% 
    left_join(meddat, by = 'sta')

  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )
  
  out <- dat %>% 
    filter(sta %in% opts$sta)

  out <- list(
    toplo = out,
    opts = opts
  )

  return(out)
  
})

# optimal effort as median of all, weighted by site distance from threshold
optwgtmed <- reactive({
  
  # inputs
  optdat <- optdat()
  
  opts <- optdat$opts

  # weighted median
  out <- weightedMedian(opts$eff, w = 1 / opts$reldif)
  
  return(out)
  
})

# text for optimal plot 1
opttxt <- reactive({
  
  # input
  powsel <- input$powsel
  smpsel <- input$smpsel
  optdat <- optdat()
  optwgtmed <- optwgtmed()
  
  smpsel <- case_when(
    smpsel == 'D' ~ 'dry', 
    smpsel == 'S' ~ 'wet'
  )
  
  opts <- optdat$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  wgtmedv <- round(optwgtmed, 2)
  out <- paste0("Optimal sample effort in ", smpsel, " weather at ", powsel, " power: ", medv , ' relative effort (weighted by distance from threshold: ', wgtmedv, ')')
  
  return(out)
  
})

# optimal plot, by constituent
optplo <- reactive({
  
  # inputs
  optdat <- optdat()
  varthr <- varthr()
  optwgtmed <- optwgtmed()
  powsel <- input$powsel

  # setup text labels in groups for plotly
  # sort out size vector for reldif if exists or not
  opts <- optdat$opts %>% 
    mutate(
      labs = paste0(sta, ', effort: ', round(eff, 2), ', change: ', chg, ', median: ', medval, ', threshold: ', varthr, ', rel. diff: ', round(reldif, 2)
                    ),
      relsz = case_when(
        is.na(reldif) ~ 1,
        !is.na(reldif) ~ reldif
      )
    )
  
  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) + 
    geom_boxplot() +
    geom_hline(yintercept = optwgtmed, col = 'red') +
    scale_y_continuous(limits = c(0.1, 2)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )

  # contour data
  toplo <- optdat$toplo

  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = sta), breaks = powsel, size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = labs, size = relsz), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_size_continuous(guide = F, trans = 'reverse', limits = c(NA, 0)) + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1, height = 150, width = 900)
  pout2 <- ggplotly(p2, height = 450, width = 900, tooltip = 'group')
  
  out <- subplot(pout1, pout2, nrows = 2, heights = c(0.1, 0.9), shareX = T, titleY = T)
  return(out)
  
})

# optimal sample effort data, all constituents
optdat2 <- reactive({
  
  # input
  powsel2 <- input$powsel2
  consel2 <- input$consel2
  smpsel <- input$smpsel
  shdsel <- input$shdsel
  
  if(shdsel == 'all')
    shdsel <- unique(pows$Watershed)
  
  if(consel2 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel2)) 
   
  dat <- pows %>% 
    filter(par %in% !!sels) %>% 
    filter(wxt %in% smpsel) %>% 
    filter(Watershed %in% shdsel)

  # get medians by station, constituent
  # estimate relative difference from threshold if available
  meddat <- medat %>% 
    filter(Parameter %in% !!sels) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Parameter) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    left_join(thrsdat, by = 'Parameter') %>% 
    mutate(
      thrdif = abs(medval - Threshold), 
      reldif = (thrdif / Threshold)
    ) %>% 
    rename(
      sta = StationCode, 
      par = Parameter
      )

  opts <- dat %>% 
    group_by(sta, par) %>% 
    nest %>% 
    mutate(
      opt = purrr::map(data, getopt, pow = powsel2)
    ) %>% 
    dplyr::select(-data) %>% 
    unnest(opt) %>% 
    dplyr::select(-opt) %>% 
    na.omit %>% 
    unite('stapar', sta, par, remove = F) %>% 
    ungroup %>% 
    left_join(meddat,by = c('sta', 'par'))

  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )
  
  out <- dat %>% 
    unite('stapar', sta, par, remove = F) %>% 
    filter(stapar %in% opts$stapar)

  selopteff <- opteff %>% 
    filter(powin %in% powsel2) %>% 
    filter(par %in% sels) %>% 
    filter(wxt %in% smpsel)
  
  out <- list(
    toplo = out,
    opts = opts, 
    selopteff = selopteff
  )
  
  return(out)
  
})

# optimal effort as median of all, weighted by site distance from threshold
optwgtmed2 <- reactive({
  
  # inputs
  optdat2 <- optdat2()
  
  opts <- optdat2$opts %>% 
    filter(!is.na(Threshold))

  # weighted median
  out <- weightedMedian(opts$eff, w = 1 / opts$reldif)
  
  return(out)
  
})

# optimal effort as median separat for each parameter, weighted by site distance from threshold
optwgtmedpar2 <- reactive({
  
  # inputs
  optdat2 <- optdat2()
  
  opts <- optdat2$opts

  # weighted median
  out <- opts %>% 
    group_by(par) %>% 
    summarise(
      wgtmed = case_when(
        anyNA(reldif) ~ median(eff, na.rm = T), 
        T ~ weightedMedian(eff, w = 1 / reldif)
      )
    )

  return(out)
  
})

# text for optimal plot 2
opttxt2 <- reactive({
  
  # input
  powsel2 <- input$powsel2
  smpsel <- input$smpsel
  optdat2 <- optdat2()
  optwgtmed2 <- optwgtmed2()
  
  smpsel <- case_when(
    smpsel == 'D' ~ 'dry', 
    smpsel == 'S' ~ 'wet'
  )
  
  opts <- optdat2$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  wgtmedv <- round(optwgtmed2, 2)
  out <- paste0("Optimal sample effort in ", smpsel, " weather at ", powsel2, " power: ", medv , ' relative effort (weighted by distance from threshold: ', wgtmedv, ')')
  
  return(out)
  
})

# optimal plot, all constituents
optplo2 <- reactive({
  
  # inputs
  optdat2 <- optdat2()
  powsel2 <- input$powsel2
  optwgtmed2 <- optwgtmed2()
  optwgtmedpar2 <- optwgtmedpar2()
  
  toplo <- optdat2$toplo
  opts <- optdat2$opts
  selopteff <- optdat2$selopteff

  # setup text labels in groups for plotly
  # sort out size vector for reldif if exists or not
  opts <- opts %>% 
    mutate(
      labs = paste0(sta, ', ', par, ' effort: ', round(eff, 2), ', change: ', chg, ', median: ', medval, ', threshold: ', Threshold, ', rel. diff: ', round(reldif, 2)
                    ),
      relsz = case_when(
        is.na(reldif) ~ max(.$reldif, na.rm = T),
        !is.na(reldif) ~ reldif
      )
    )

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) + 
    geom_boxplot() +
    geom_hline(yintercept = optwgtmed2, color = 'red') +
    scale_y_continuous(limits = c(0.1, 2)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )
  
  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = stapar), breaks = powsel2, size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = labs, size = relsz), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    scale_size_continuous(guide = F, trans = reverselog_trans(10)) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1)#, height = 150, width = 900)
  pout2 <- ggplotly(p2, tooltip = 'group')#, height = 450, width = 900)
  
  pout3 <- plot_ly() %>% 
    add_trace(data = selopteff, y = ~par, x = ~eff, type = 'box', text = ~sta, boxpoints = 'all', jitter = 0.3, pointpos= 0, orientation = 'h') %>%
    add_trace(data = optwgtmedpar2, y = ~par, x = ~wgtmed, type= 'box', color = I('red'), text = NULL) %>% 
  layout(
    yaxis = list(title = ''), 
    xaxis = list(title= 'Optimal effort by site'), 
    showlegend = F
    )

  out <- subplot(pout3, pout1, pout2, nrows = 3, heights = c(0.45, 0.1, 0.45), shareX = T, titleY = T)
  return(out)
  
})

# tabular data for optimal effort for grouped constituents
opttab2 <- reactive({
  
  optdat2 <- optdat2()

  totab <- optdat2$opts %>% 
    select(par, sta, eff, medval, Threshold, thrdif, reldif)
  
  out <- reactable(totab, 
                   groupBy = 'par', 
                   columns = list(
                     par = colDef(name = 'Constituent'),
                     sta = colDef(name = 'Station'),
                     eff = colDef(name = 'Optimal effort'),
                     medval = colDef(name = 'Median value at station'),
                     thrdif = colDef(name = 'Diff. of median from threshold'),
                     reldif = colDef(name = 'Relative difference for weighting')
                   ),
                   defaultColDef = colDef(
                     footerStyle = list(fontWeight = "bold"),
                     format = colFormat(digits = 2, separators = TRUE),
                     resizable = TRUE
                     )
  )
  
  return(out)
  
})

# all trends across stations for selected constituent
alltrnd <- reactive({
  
  # input
  varsel3 <- input$varsel3
  
  out <- medat %>%
    filter(Parameter %in% varsel3) %>%
    mutate(
      Year = year(Date),
      Month = month(Date, label = T)
    ) %>%
    group_by(StationCode, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(StationCode) %>%
    # filter(n() == 10) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){

        nval <- nrow(na.omit(x))
        knout <- try(kendallTrendTest(dev ~ Year, x), silent = T)
        outpval <- try(p_ast(knout$p.value), silent = T)
        
        if(!inherits(outpval, 'try-error')){
          
          outest <- round(knout$estimate, 2)
          out <- c(n = nval, outest, pval = outpval) %>%
            data.frame %>%
            t %>%
            data.frame %>%
            select(-intercept) %>% 
            mutate_if(is.factor, function(x) as.character(x))
          
        }
        
        if(inherits(outpval, 'try-error')){
          
          out <- data.frame(n = nval, tau = NA, slope = NA, pval = NA)
          
        }
 
        return(out)
        
      })
    ) %>%
    select(-data) 
  
  res <- do.call('rbind', out$res)
  out <- out %>% 
    select(-res) %>% 
    bind_cols(res) %>% 
    mutate(
      trend = ifelse(tau < 0, 'dec', 'inc'), 
      slope = as.numeric(slope),
      n = as.numeric(n),
      tau = as.numeric(tau)
    ) %>% 
    ungroup()

  return(out)
  
})

# table for all trends
alltrndtab <- reactive({
  
  # input
  alltrnd <- alltrnd()
  
  totab <- alltrnd
  
  HTML(knitr::kable(totab, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))

})

# map for all trends
alltrndmap <- reactive({

  # input
  alltrnd <- alltrnd()

  locs <- medat %>%
    select(StationCode, Longitude, Latitude) %>%
    unique

  tomap <- alltrnd %>%
    left_join(locs, by = 'StationCode') %>%
    na.omit %>% 
    st_as_sf(coords = c("Longitude", "Latitude"), crs = prj)

  # point colors
  cols <- tomap %>%
    mutate(
      cols = factor(trend, levels = c('dec', 'inc'), labels = c('lightgreen', 'tomato1')),
      cols = as.character(cols)
    ) %>%
    pull(cols)

  # size values
  cexv <- tomap %>%
    pull(tau) %>%
    abs %>%
    scales::rescale(to = c(2, 15))

   # hover pt labels
  labs <- paste(tomap$StationCode, ': ', tomap$trend, ', tau = ', tomap$tau, ', p = ', tomap$pval)
  mapviewOptions(leafletHeight = 500)

  out <- mapview(tomap, zcol = 'tau', cex = cexv, label = labs, col.regions = cols, legend = F, map.types = mptyps)@map

  return(out)

})
```

## Inventory {.tabset .tabset-pills}

### Maps

Watersheds monitored, number of parameters measured, and number of years monitored at each station. 

```{r}
tomap <- medat %>% 
  select(StationCode, Watershed, Longitude, Latitude) %>% 
  unique %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m1a <- mapview(tomap, zcol = 'Watershed', layer.name = 'Watershed location', homebutton = F, map.types = mptyps)

tomap <- medat %>% 
  select(StationCode, Parameter, Longitude, Latitude) %>% 
  unique %>% 
  group_by(StationCode, Longitude, Latitude) %>% 
  summarise(n = n()) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m2a <- mapview(tomap, zcol = 'n', layer.name = 'Number of parameters', homebutton = F, col.regions = magma, map.types = mptyps)

tomap <- medat %>% 
  select(StationCode, yr = Date, Longitude, Latitude) %>% 
  mutate(yr = year(yr)) %>% 
  unique %>% 
  group_by(StationCode, Longitude, Latitude) %>% 
  summarise(n = n()) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m3a <- mapview(tomap, zcol = 'n', layer.name = 'Number of years', homebutton = F, col.regions = magma, map.types = mptyps)

leafsync::sync(m1a, m2a, m3a, ncol = 1) 
```

### Tabular

```{r}
column(12, 
       column(4,
         selectInput('consel1', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs') 
       ),
       column(4, 
         selectInput('tabtyp', 'Table type:', choices = c('Number of observations', 'Variance', 'Median absolute deviation'))
       )
)
```

```{r}
renderUI(invtab())
```

## Trends and power analyses {.tabset .tabset-pills}

```{r}
column(12, 
  column(6, 
       selectInput('consel2', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs')
  ),
  column(6, 
       selectInput('shdsel', 'Select watershed:', choices = c('all', unique(pows$Watershed)))
      )
  
)

column(12,
  column(6, 
       renderUI({
       
         req(input$varsel)
         
         # input
         varsel <- input$varsel
         shdsel <- input$shdsel
         
         if(shdsel == 'all')
           shdsel <- unique(pows$Watershed)
         
         sels <- medat %>% 
           filter(Parameter %in% varsel) %>% 
           filter(Watershed %in% shdsel) %>% 
           pull(StationCode) %>% 
           unique
         
         selectInput('stasel', 'Select station:', choices = sels)  
         
       })
  ),
  column(6, 
       renderUI({
       
         # input
         consel2 <- input$consel2
         
         sels <- eval(parse(text = consel2))
         selectInput('varsel', 'Select constituent:', choices = sels)
         
       })
  )
)

column(12, 
  column(6, 
       selectInput('smpsel', 'Select sampling weather:', choices = list('dry' = 'D', 'storm'= 'S'))
  )
)
```

### Observed

Observed time series for `r renderText(input$varsel)` at `r renderText(input$stasel)`.

```{r}
renderPlot({obsp1()}, height = 350, width = 700)
renderPlot({obsp2()}, height = 300, width = 700)
renderPlot({obsp3()}, height = 300, width = 700)
```

### Trends

```{r}
renderPlot({trndp1()}, height = 350, width = 900)
```

This table shows the regression results from the above plot.

```{r, results='asis'}
renderUI({trndtab1()})
```

The plots below show the observed time series (left) with measurements averaged to year/month (left) and a moving window average for a 12 month period with deviations around the average (right).

```{r}
renderPlot({trndp2()}, height = 350, width = 900)
```

Kendall tests also provide an indication of a trend by evaluating magnitude, direction, and significance of a change in density between the selected years. The test is a non-parametric equivalent to the regression analysis above. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

```{r, results = 'asis'}
renderUI({trndtab2()})
```

### Power analyses

A power analysis was conducted to estimate the ability to detect a specific trend for a desired sampling frequency.  This analysis involved repeated simulations of time series with similar characteristics as the data observed at station SDMF05.  Generally, power is described as the likelihood of observing an actual trend given the magnitude of the trend and sampling frequency.  __For all scenarios, sampling frequency is expressed as a proportion of the observed effort, with sampling at 100% effort equal to site visits every ~14 days across the period of record.__  Power is expected to decrease with decreasing trend magnitudes and decreasing sampling frequency.

The observed time series for `r renderText({input$varsel})` at `r renderText({input$stasel})` is shown below.  The power analyses are specific to the characteristics of the time series at this station.

```{r}
renderPlot({powplo1()}, height = 350, width = 900)
```

This plot shows 20 simulated time series of `r renderText(input$varsel)` trends that are based on variance estimates from the observed time series.  Four types of simulations are shown.  In the top left, a trend of 30\% change from the original value is shown with a sampling effort of 30\% that of the original time series. In the top right, a trend of 30\% change from the original value is shown with a sampling effort of 100\% that of the original time series. In the bottom left, a trend of 100\% change from the original value is shown with a sampling effort of 30\% that of the original time series. In the bottom left, a trend of 100\% change from the original value is shown with a sampling effort of 10\% that of the original time series. Lines in red are significant ($\alpha$ = 0.05) based on results of a linear trend analysis.  The total power is based on the number of significant results for each scenario divided by the total number of simulations (n = 20 for each).  As such, increasing power is observed with stronger trends and higher sampling densities.

```{r}
renderPlot({powplo2()}, height = 550, width = 900)
```

This plot shows a summary of power for several efforts and trends. Power is based on 1000 simulations for each scenario (differing from the example above).

```{r}
renderPlot({powplo3()}, height =650, width = 900)
```

A second power analysis was conducted to identify the ability to observe an exceedance for a `r renderText(input$varsel)` concentration for a given sample density.  This provides an indication of how likely you are to detect a concentration above a value of interest within your sampling design.  The top left shows the power of observing an exceedance of 1 mg/L at 10\% sample effort.  The top right shows the power of observing an exceedance of 1 mg/L at 100\% sample effort. The bottom left shows the power of observing an exceedance of 10 mg/L at 10\% sample effort. The bottom right shows the power of observing an exceedance of 10 mg/L at 100\% sample effort.  Observations above the threshold are shown in red.

```{r}
renderPlot({powplo4()}, height = 550, width = 900)
```

This plot shows the uncertainty associated with the average esimated concentration within each year.  The estimates served as a proxy for power given the sample effort and exceedance threshold.

```{r}
renderPlot({powplo5()}, height = 550, width = 900)
```

Finally, power to detect observations above a given threshold is summarized below across different levels of effort and thresholds. Power is based on 1000 simulations for each scenario (differing from the example above).

```{r}
renderPlot({powplo6()}, height = 650, width = 900)
```


### Optimal effort by constituent

Optimal sample effort was determined for all stations and a selected constituent (`r renderText({input$varsel})`) using power results for the ability to detect a specified trend (first power analysis).  For all power curves for the constituent, a desired level of power is chosen (`r renderText({input$powsel})`).  All power curves are then plotted that meet the criteria of being monotonic across all levels of sample effort for which power was estimated (some were non-monotonic due to stochastic sub-sampling and/or insufficient data).   

The "optimal" level of sampling for each station is estimated as the point which the slope of y ~ x exceeds that of x ~ y, such that further reductions in sample effort (x) caused disproportionate increases in magnitude of the trend (y) for the desired power (`r renderText(input$powsel)`).  In other words, optimal was defined as the maximum reduction in sample effort where the increase in the magnitude of the trend change did not increase substantially relative to the reduction in sample effort.  The optimal level of effort for the constituent is then summarized across all stations on the top marginal boxplot, i.e., the median optimal value across all stations. 

An alternative "optimal" level was also defined as the weighted median of the optimal effort for each station.  This value is shown by the __red__ vertical line.  The weights are defined as the distance of the median observation for a constituent at a station relative to a threshold, with higher weights assigned to stations with median values closer to the threshold.  Higher weights mean the optimal effort at that station is given higher importance for determining the median value.  

```{r}
column(12, 
       column(4, selectInput('powsel', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

`r renderText(opttxt())`

```{r}
renderPlotly(optplo())
```

<br>
<br>
Note: Changing the station selection above does not affect the estimates since the optimal level is an aggregate across stations.  

### Optimal effort across constituents

This is the same plot as the previous tab, except power curves that satisfy the requirement for estimating optimal power are combined across constituents for the selected constituent type.  The top plot shows boxplot distributions of optimal power efforts for each station separated by constituent.  The middle boxplot shows the distrubution after combining optimal efforts across constituents.  The optimal effort is the median of all optimal efforts combined.  The bottom plot shows power curves for all stations and constituents with the grey points indicating the optimal effort. 

The optimal sample effort weighted by site distances from a threshold is also shown with the vertical __red__ line, shown overall across all constituents and separately for individual constituents. The weights for the weighted median shown in the red line are defined as the distance of the median observation for a constituent at a station relative to a threshold, with higher weights assigned to stations with median values closer to the threshold.  Higher weights mean the optimal effort at that station is given higher importance for determining the median value.  

```{r}
column(12, 
       column(4, selectInput('powsel2', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

`r renderText(opttxt2())`

```{r}
output$optplo2 <- renderPlotly(optplo2())
plotlyOutput('optplo2', height = '700px')
```

<br>
<br>
Note: Changing the station and constituent selection above does not affect the estimates since the optimal level is an aggregate across stations and constituents for the selected constituent type.  

Tabular data below shows the same results from the plot. 

```{r}
output$opttab2 <- renderReactable(opttab2()) 
fillCol(
  reactableOutput('opttab2')
)
```

## Station differences {.tabset .tabset-pills}

```{r, fig.height = 5, fig.width = 6, fig.align = 'center'}
# rename some nutrient parameters
meprp <- medat %>% 
  filter(!StationCode %in% 'SICG03') %>% 
  mutate(
    Date = floor_date(Date, unit = 'month')
  ) %>% 
  filter(Parameter %in% c(metals, nutrs, organs)) %>% 
  select(Watershed, StationCode, Date, Parameter, Result) %>% 
  group_by(Watershed, StationCode, Date, Parameter) %>% 
  summarise(Result = mean(Result, na.rm = T)) %>% 
  group_by(StationCode, Parameter) %>% 
  mutate(Result = case_when(
    is.na(Result) ~ mean(Result, na.rm = T), 
    T ~ Result
    )
  ) %>% 
  ungroup() 

siteshd <- meprp %>% 
  select(Watershed, StationCode) %>% 
  unique
```

```{r}
column(12,
  column(6,
        selectInput('consel3', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs')
         ),
  column(6,
         renderUI({
           
           # input
           consel3 <- input$consel3
         
           if(consel3 == 'organs')
             sels <- c('GLYP', 'Malathion')
           else 
            sels <- eval(parse(text = consel3))
           
           selectInput('varsel2', 'Select constituent:', choices = sels)
           
         })
  )
)
column(12, 
  column(6, 
       selectInput('stasel2', 'Select first station:', choices = unique(pows$sta), selected = 'SDMF05')
  ), 
  column(6, 
       selectInput('stasel3', 'Select second station:', choices = unique(pows$sta), selected = 'SADF01')
  )
)
```

### By constituent {.tabset .tabset-pills}

This plot shows a PCA comparison of all sites, dates, and constituents and a dissimilarity matrix for `r renderText({input$varsel2})` between the time series at each station.  Blue tiles are more similar and red are more dissimilar.  

```{r}
renderPlot({mulplo()}, height = 550, width = 900)
```

```{r}
column(12, 
       column(6, 
              renderUI({
                
                # input
                disdat <- disdat()
                
                rng <- disdat %>% 
                  filter(!is.na(dist)) %>% 
                  group_by(StationCode) %>% 
                  summarise(dist = mean(dist, na.rm = T)) %>% 
                  pull(dist)

                rng <- round(range(rng, na.rm = T), 1)
                med <- round(rng[1] + ((rng[2] - rng[1]) / 2), 1)
              
                sliderInput('unithr', 'Select unique threshold:', min = rng[1], max = rng[2], value = med)  
              })
      )
)
```

```{r}
renderUI(unisel())
```

Observed time series for selected stations and constituent.

#### Time series

```{r}
renderPlot({obsp4()}, height = 450, width = 700)
```

#### By year

```{r}
renderPlot({obsp5()}, height = 450, width = 700)
```

#### By month

```{r}
renderPlot({obsp6()}, height = 450, width = 700)
```

### Across constituents 

```{r}
column(12, 
       column(6, 
              renderUI({
                
                # input
                discondat <- discondat()
                
                rng <- discondat %>% 
                  pull(dist) 

                rng <- round(range(rng, na.rm = T), 2)
                med <- round(rng[1] + ((rng[2] - rng[1]) / 2), 2)
              
                sliderInput('unithr2', 'Select unique threshold:', min = rng[1], max = rng[2], value = med)  
                
              })
      )
)
```

This selection is the same as in the previous tab, except the average represents the grand mean of dissimilarities across all constituents and stations for the selected constituent type. 

```{r}
renderUI(unisel2())
```

## Overall trends

```{r}
column(12, 
  column(6, 
       selectInput('consel4', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'),  selected = 'nutrs')
  ),
  column(6, 
       renderUI({
       
         # input
         consel4 <- input$consel4

         if(consel4 == 'organs')
             sels <- c('GLYP', 'Malathion')
           else 
            sels <- eval(parse(text = consel4))
           
         sels <- eval(parse(text = consel4))
         selectInput('varsel3', 'Select constituent:', choices = sels)
         
       })
  )
)

```

Kendall tests provide an indication of a trend by evaluating magnitude, direction, and significance of a change in density between the selected years. The test is a non-parametric equivalent to the regression analysis above. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

The maps show the value for tau (direction of trend) for a Kendall test for changes across stations, green for decreasing and red for increasing. Size of the point is the magnitude of the estimated change between.  The table shows the detailed results from the map.

```{r}
renderLeaflet(alltrndmap())
```

```{r}
renderUI(alltrndtab())
```
