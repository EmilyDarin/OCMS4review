---
output: 
    html_document:
        css: styles.css
runtime: shiny
---

# OC MS4 monitoring program, mass emissions {.tabset}

```{r setup, message = F, warning = F, results = 'hide', echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, echo = F, fig.path = 'figs/', dev.args = list(family = 'serif'))

library(tidyverse)
library(sf)
library(mapview)
library(lubridate)
library(leaflet)
library(leafsync)
library(viridisLite)
library(lubridate)
library(gridExtra)
library(stargazer)
library(EnvStats)
library(shiny)
library(kableExtra)
library(mgcv)
library(metR)
library(vegan)
library(ggord)
library(patchwork)
library(ggrepel)
library(ggExtra)
library(plotly)
library(matrixStats)
library(scales)
library(reactable)

mptyps <- c("CartoDB.Positron", "CartoDB.DarkMatter", "OpenStreetMap", "Esri.WorldImagery", "OpenTopoMap")

mapviewOptions(leafletHeight = 300)

prj <- 4326 # wgs84

source('R/funcs.R')

##
# ggplot themes

thm1 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    strip.text = element_text(hjust = 0),
    axis.title.x = element_blank(), 
    legend.title = element_blank(), 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm2 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm3 <- theme_bw(base_size = 12) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

pbase <- theme_bw(base_family = 'serif') +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10), 
    axis.text.y = element_text(size = 10),
    legend.position = 'top',
    legend.direction = 'horizontal',
    # plot.margin = unit(c(4,4,0,0), "lines"),
    strip.background = element_blank(), 
    strip.text.y = element_text(angle = 0, hjust = 0, vjust = 0.5), 
    panel.background = element_rect(fill = 'black')
  ) 

data(medat)
data(methrsdat)
data(pows)
data(thrs)
data(opteff)

reverselog_trans <- function(base = exp(1)) {
    trans <- function(x) -log(x, base)
    inv <- function(x) base^(-x)
    trans_new(paste0("reverselog-", format(base)), trans, inv, 
              log_breaks(base = base), 
              domain = c(1e-100, Inf))
}

# smpsel choices
wx <- list('dry' = 'D', 'storm'= 'S')

# constituents
metals <- c("Ag", "As", "Cd", "Cr", "Cu", "Fe", "Hg", "Ni", "Pb", "Se", 
            "Zn")
organs <- c("Azinphos methyl (Guthion)", "Bolstar", "Chlorpyrifos", "Coumaphos", 
            "Demeton-o", "Demeton-s", "Diazinon", "Dichlorvos", "Dimethoate", 
            "Disulfoton", "Ethoprop", "Ethyl Parathion", "Fensulfothion", 
            "Fenthion", "GLYP", "Malathion", "Merphos", "Mevinphos", 
            "Parathion-methyl", "Phorate", "Ronnel", "Tetrachlorovinphos", 
            "Tokuthion", "Trichloronate")
nutrs <- c('Ammonia', 'Nitrate, Nitrite', 'Total Kjeldahl Nitrogen', 'Orthophosphate', 'Total Phosphorus')
```

```{r reactives}
# inventory table
invtab <- reactive({
  
  # input
  consel1 <- input$consel1
  tabtyp <- input$tabtyp


  # filter by parameters
  tofilt <- eval(parse(text = consel1))
  sums <- medat %>% 
    filter(Parameter %in% tofilt)
  
  if(tabtyp == 'Number of observations'){
    
    sums <- sums %>% 
      dplyr::count(Parameter, StationCode) %>% 
      bind_rows(group_by(., Parameter) %>%
                summarise(n=sum(n)) %>%
                mutate(StationCode='Total')) %>%
      bind_rows(group_by(., StationCode) %>%
                summarise(n=sum(n)) %>%
                mutate(Parameter='Total')) %>%
      spread(Parameter, n, fill=0) %>% 
      select_at(c('StationCode', tofilt, 'Total'))
  
    alltot <- sums %>% 
      filter(StationCode != 'Total')
    coltot <- sums %>% 
      filter(StationCode == 'Total')
    
    totab <- bind_rows(alltot, coltot)
    
    cap <- 'Number of observations at each site'
  
  }
        
  if(tabtyp == 'Variance'){
    
    totab <- sums %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(vr = round(var(Result, na.rm = T), 2)) %>% 
      spread(Parameter, vr, fill = NA)
    
    cap <- 'Variance at each site'
    
  }
  
  if(tabtyp == 'Median absolute deviation'){
    
    totab <- sums %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(md = round(mad(Result, na.rm = T), 2)) %>% 
      spread(Parameter, md, fill = NA)
    
    cap <- 'Median absolute deviation at each site'
    
  }
  
  HTML(knitr::kable(totab, format = 'html', caption = cap) %>% 
      kable_styling(full_width = T, font_size = 14))  
    
})

# selected station, parameter data
stapardat <- reactive({
  
  # inputs
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel

  req(varsel)
  req(stasel)
  
  out <- medat %>% 
    filter(StationCode %in% stasel) %>% 
    filter(Parameter %in% varsel) %>% 
    filter(Type %in% smpsel) %>% 
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection', 
        T ~ 'within range'
      ),
      Detection = factor(Detection, levels = c('below detection', 'within range')),
      Year = year(Date), 
      Month = month(Date, label = T)
    ) 

  validate(
    need(nrow(out) > 0, 'No data in selection')
  )    
  
  return(out)
  
})

# first observed plot
obsp1 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)
  
  p <- ggplot(toplo, aes(x = Date, y = Result)) + 
    geom_line() + 
    geom_point(aes(colour = Detection)) + 
    thm1 + 
    # scale_y_log10() + 
    scale_colour_manual(values = c('tomato1', 'black'), drop = F) + 
    labs(
      subtitle = stasel, 
      title = ttl, 
      y = 'Concentration (mg/L)'
    )
  
  return(p)
  
})

# second observed plot
obsp2 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) + 
    geom_boxplot() + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      subtitle = stasel,
      title = paste(ttl, 'by year'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# third observed plot
obsp3 <- reactive({
  
  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) + 
    geom_boxplot() + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      subtitle = stasel, 
      title = paste(ttl, 'by month'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# trend data
trnddat <- reactive({
  
  # input
  stapardat <- stapardat()
  
  out <- try({stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    ungroup %>%
    mutate(
      avg = round(avg, 2),
      Parameter = paste0(Parameter, ' (', avg, ')')
    )
  })
  
  return(out)
  
})

# first trend plot
trndp1 <- reactive({
  
  # input
  trnddat <- trnddat()
  stasel <- input$stasel
  
  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )
  
  subttl <- paste0(stasel, ', average in parentheses on y-axis')
  
  p <- ggplot(trnddat, aes(x = Year, y = dev, fill = dev)) +
    geom_bar(stat = 'identity', colour = 'grey') +
    scale_fill_gradient2('Deviations from average (+/-)', low = 'tomato1', mid = 'grey90', high = 'lightgreen', midpoint = 0) +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(axis.title.y = element_blank()) +
    geom_smooth(method = 'lm', se = F, linetype = 'dashed', color = 'black') +
    # scale_y_log10() +
    # scale_y_continuous('Density (fish/100ft)') +
    geom_hline(aes(yintercept = 0)) +
    labs(
      title = 'Deviation from annual averages by constituent (mg/L)',
      subtitle = subttl
    ) + 
    guides(fill = guide_colourbar(barwidth = 15, barheight = 0.5))
  
  return(p)
    
})

# first trend table
trndtab1 <- reactive({
  
  # input
  trnddat <- trnddat()
  
  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )
  
  mods <- trnddat %>%
    group_by(Parameter) %>%
    nest %>%
    mutate(
      mod = purrr::map(data, function(x) lm(dev ~ Year, x))
    ) %>%
    ungroup %>%
    mutate(
      Parameter = gsub('\\s\\(.*\\)$', '', Parameter)
    )
  
  out <- stargazer(mods$mod, type = 'html',
            covariate.labels = c('Year', 'Intercept'),
            column.labels = mods$Parameter,
            omit.stat = c('adj.rsq', 'ser'),
            column.sep.width = '10pt',
            dep.var.labels.include = F,
            digits = 2
            ) %>% 
    HTML()
  
  return(out)

})

# second trend plot
trndp2 <- reactive({
  
  # input
  stapardat <- stapardat()
  stasel <- input$stasel
  varsel <- input$varsel
  
  win <- 12
  toplo <- try({stapardat %>%
    select(Date, Parameter, Result) %>%
    mutate(Date = floor_date(Date, unit = 'month')) %>%
    group_by(Date, Parameter) %>%
    summarise(Result = mean(Result, na.rm = T)) %>%
    # group_by(Parameter) %>%
    arrange(Parameter, Date) %>%
    group_by(Parameter) %>%
    mutate(
      avg = stats::filter(Result, rep(1, win)/win, sides = 1, method = 'convolution')
    ) %>%
    ungroup %>%
    mutate(
      dev = Result - avg
    )})
  
  # cut if no data
  validate(
    need(!inherits(toplo, 'try-error'), 'Insufficient data')
  )
  
  p1 <- ggplot(toplo, aes(x = Date, y = Result)) +
    geom_line() +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(axis.title.y = element_blank()) +
    # scale_y_log10() +
    labs(
      title = paste0('Observed ', varsel),
      subtitle = stasel,
      ylab = 'Concentration (mg/L)'
    )

  p2 <- ggplot(toplo, aes(x = Date, y = avg)) +
    geom_segment(aes(x = Date, xend = Date, yend = avg, y = avg + dev, colour = dev), size = 0.8) +
    geom_line(colour = 'black') +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(legend.position = 'right') +
    # scale_y_log10() +
    scale_colour_gradient2('Devation from average (+/-)', low = 'tomato1', mid = 'grey90', high = 'lightgreen', midpoint = 0) +
    labs(
      title = 'Deviations from annual average',
      subtitle = stasel,
      ylab = NULL
    )

  grid.arrange(
    arrangeGrob(p1, p2, ncol = 2, widths = c(0.8,1))
  )
  
})

# second trends table
trndtab2 <- reactive({
  
  # input
  stapardat <- stapardat()
  
  totabs1kn <- stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){
  
        knout <- kendallTrendTest(dev ~ Year, x)
        outest <- round(knout$estimate, 2)
        outpval <- p_ast(knout$p.value)
        nval <- nrow(na.omit(x))
        out <- c(n = nval, outest, pval = outpval) %>%
          data.frame %>%
          t %>%
          data.frame %>%
          select(-intercept)
        return(out)
  
      })
  
    ) %>%
    select(-data) %>%
    unnest(res)

  out <- HTML(knitr::kable(totabs1kn, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))
  
  return(out)
  
})

# power analysis data
powdat <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel
  
  req(varsel)
  req(stasel)

  out <- medat %>%
    filter(StationCode %in% stasel) %>%
    filter(Parameter %in% varsel) %>%
    filter(Type %in% smpsel) %>% 
    mutate(
      Year = year(Date),
      Season = yday(Date),
      dectime = decimal_date(Date)
    )

  return(out)
  
})

# first power analysis plot
powplo1 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  powdat <- powdat()
  
  p <- ggplot(powdat, aes(x = Date, y = Result)) +
    geom_line() +
    thm2 +
    scale_y_log10() +
    labs(
      title = 'Observed time series',
      subtitle = stasel,
      xlab = NULL,
      y = paste0(varsel, ' (mg/L)')
    )
  
  return(p)
  
})

# third power plot
powplo3 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  smpsel <- input$smpsel
  
  toplo <- pows %>% 
    filter(sta %in% stasel) %>% 
    filter(par %in% varsel) %>% 
    filter(wxt %in% smpsel)
  
  p <- ggplot(toplo, aes(x = eff, y = chg, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    # scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Magnitude of trend change (%) of ', varsel),
      title = paste0('Power estimates for ', stasel),
      subtitle = 'Lines show power for varying sample effort and trend magnitude',
      x = 'Relative sample effort'
    )
  
  p
  
})

# sixth power plot
powplo6 <- reactive({
  
  # input
  stasel <- input$stasel
  varsel <- input$varsel
  
  toplo <- thrs %>% 
    filter(StationCode %in% stasel) %>% 
    filter(Parameter %in% varsel) 
  
  p <- ggplot(toplo, aes(x = effs, y = vals, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Concentration of ', varsel),
      title = paste0('Power estimates for ', stasel),
      subtitle = 'Lines show the likelihood that the true mean for the sample is above the threshold',
      x = 'Relative sample effort'
    )

  p
  
})

# comparison of time series for stations
stapardat2 <- reactive({
  
  # inputs
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2

  req(varsel2)
  
  out <- medat %>% 
    filter(StationCode %in% c(stasel2, stasel3)) %>% 
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection', 
        T ~ 'within range'
      ),
      Year = year(Date), 
      Month = month(Date, label = T), 
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    ) %>%
    filter(Parameter %in% varsel2)
    
  return(out)
  
})

# fourth observed plot
obsp4 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)
  
  p <- ggplot(toplo, aes(x = Date, y = Result)) + 
    geom_line() + 
    geom_point(aes(colour = Detection)) + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 + 
    # scale_y_log10() + 
    scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = ttl, 
      y = 'Concentration (mg/L)'
    )
  
  return(p)
  
})

# fifth observed plot
obsp5 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) + 
    geom_boxplot() + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = paste(ttl, 'by year'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# sixth observed plot
obsp6 <- reactive({
  
  # inputs
  stapardat2 <- stapardat2()
  
  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) + 
    geom_boxplot() + 
    facet_wrap(~StationCode, ncol = 1) + 
    thm1 +
    # scale_y_log10() + 
    # scale_colour_manual(values = c('tomato1', 'black')) + 
    labs(
      title = paste(ttl, 'by month'), 
      y = 'Concentration (mg/L)'
    )

  return(p)
  
})

# dissimilarity data
disdat <- reactive({
  
  # input
  varsel2 <- input$varsel2
  
  req(varsel2)

  dissim <- meprp %>% 
    filter(Parameter %in% varsel2) %>% 
    select(-Watershed, -Parameter) %>% 
    spread(StationCode, Result) %>% 
    column_to_rownames('Date') %>% 
    decostand(method = 'log', na.rm = T) %>% 
    decostand(method= 'standardize', na.rm = T) %>%
    rownames_to_column('Date') %>% 
    gather('StationCode', 'Result', -Date) %>% 
    spread(Date, Result) %>% 
    column_to_rownames('StationCode') %>% 
    vegdist(method = 'euclidean', na.rm = T) %>%
    as.matrix %>%
    as.data.frame %>%
    rownames_to_column('StationCode') %>%
    gather('StationCode2', 'dist', -StationCode) %>%
    left_join(siteshd, by = 'StationCode') %>%
    arrange(Watershed, dist) %>%
    mutate(
      Watershed = factor(Watershed, levels = unique(Watershed)),
      dist = ifelse(StationCode == StationCode2, NA, dist)
    )
  
  return(dissim)

})

# dissimilarity data, all constituents
discondat <- reactive({
   
  # input
  consel3 <- input$consel3
  
  if(consel3 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel3))
           
  dissim <- meprp %>% 
    filter(Parameter %in% sels) %>% 
    select(-Watershed) %>% 
    group_by(Parameter) %>% 
    nest() %>% 
    mutate(
      dis = purrr::map(data, function(data){
        
        out <- data %>% 
          spread(StationCode, Result) %>% 
          column_to_rownames('Date') %>% 
          decostand(method = 'log', na.rm = T) %>% 
          decostand(method= 'standardize', na.rm = T) %>%
          rownames_to_column('Date') %>% 
          gather('StationCode', 'Result', -Date) %>% 
          spread(Date, Result) %>% 
          column_to_rownames('StationCode') %>% 
          vegdist(method = 'euclidean', na.rm = T) %>%
          as.matrix %>%
          as.data.frame %>%
          rownames_to_column('StationCode') %>%
          gather('StationCode2', 'dist', -StationCode) %>%
          left_join(siteshd, by = 'StationCode') %>%
          arrange(Watershed, dist) %>%
          mutate(
            Watershed = factor(Watershed, levels = unique(Watershed)),
            dist = ifelse(StationCode == StationCode2, NA, dist)
          )
        
        return(out)
        
      })
    ) %>% 
    select(-data) %>% 
    unnest(dis) %>% 
    na.omit %>% 
    group_by(Parameter, StationCode) %>% 
    summarise(dist = mean(dist, na.rm = T)) %>% 
    group_by(StationCode) %>% 
    summarise(dist = mean(dist, na.rm = T))
    
  return(dissim)
  
})

# multivariate comparison plots
mulplo <- reactive({
  
  # input
  disdat <- disdat()
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2
  consel3 <- input$consel3
  
  req(varsel2)
  
  ##
  # PCA
         
  if(consel3 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel3))
           
  toord <- meprp %>% 
    filter(Parameter %in% !!sels) %>% 
    spread(Parameter, Result) %>% 
    na.omit %>%
    unite('rwnm', StationCode, Date) %>% 
    column_to_rownames('rwnm')
  wshd <- toord$Watershed
  toord <- toord %>% 
    select(-Watershed) %>% 
    decostand(method = 'log', na.rm = T) %>% 
    decostand(method= 'standardize', na.rm = T) %>% 
    select(which(!is.na(apply(., 2, var))))

  ord <- toord %>% 
    prcomp(scale. = T, center = T)

  # station subset
  vals <- ord$x %>% 
    as.data.frame %>% 
    rownames_to_column() %>% 
    mutate(StationCode = gsub('^(.*)\\_.*$', '\\1', rowname)) %>% 
    filter(StationCode %in% c(stasel2, stasel3)) %>% 
    rename(
      one = PC1, 
      two = PC2
    ) %>% 
    mutate(
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    )

  p1 <- ggord(ord, size = 1, grp_in = wshd, alpha = 0.4, vec_ext = 5, coord_fix = F) + 
    scale_fill_viridis_d(guide_legend(ncol = 1)) + 
    geom_point(data = vals, aes(alpha = StationCode), size = 3) +
    scale_alpha_manual(values = c(0.2, 0.8)) + 
    theme(
      legend.position = 'top',
      legend.title = element_blank(),
      legend.box = 'vertical'
      )
  
  ##
  # dissimilarity data and plots
  outplo <- disdat %>% 
    filter(StationCode %in% stasel2) %>% 
    filter(StationCode2 %in% stasel3)
  
  # dissimilarity ranges
  disrng <- range(disdat$dist, na.rm = T)
  
  dismid <- disrng[1] + (disrng[2] - disrng[1]) / 2
  subttl <- paste0("Dissimilarity between ", stasel2, " and ", stasel3, " ", round(outplo$dist, 1))
  
  p2 <- ggplot(disdat) +
    geom_tile(aes(x = StationCode, y = StationCode2, fill = dist), colour = 'black') +
    geom_tile(data = outplo, aes(x = StationCode, y = StationCode2), fill = NA, colour = 'black', size = 2) +
    scale_x_discrete('', expand = c(0, 0)) +
    scale_y_discrete('', expand = c(0, 0)) +
    scale_fill_gradient2('Dissimilarity between stations', low = 'lightblue', mid = 'white', high = 'tomato1', midpoint = dismid, limits = disrng) +
    guides(fill = guide_colourbar(barheight = 0.5, barwidth = 10, label.theme = element_text(size = 11, angle = 0))) +
    labs(
      title = varsel2, 
      subtitle = subttl
    ) +
    pbase

  p1 + p2 + plot_layout(ncol = 2)
      
})

# treshold value for constituent
varthr <- reactive({
  
  # input
  varsel <- input$varsel

  out <- methrsdat %>% 
    filter(par %in% varsel) %>% 
    select(-par)
  
  return(out)
  
})

# optimal sample effort data
optdat <- reactive({
  
  # input
  varthr <- varthr()
  varsel <- input$varsel
  powsel <- input$powsel
  smpsel <- input$smpsel
  shdsel <- input$shdsel

  if(shdsel == 'all')
    shdsel <- unique(pows$Watershed)
  
  dat <- pows %>% 
    filter(par %in% varsel) %>% 
    filter(wxt %in% smpsel) %>% 
    filter(Watershed %in% shdsel)

  # get median values of constituent for each station
  # calculate diff from threshold
  meddat <- medat %>% 
    filter(Parameter %in% varsel) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    rename(sta = StationCode) %>% 
    left_join(varthr, by = 'sta') %>% 
    mutate(
      thrdif = abs(medval - Threshold),
      reldif = (thrdif / Threshold)
    )
  
  opts <- dat %>% 
    group_by(sta) %>% 
    nest %>% 
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel))
    ) %>% 
    dplyr::select(-data) %>% 
    unnest(opt) %>% 
    dplyr::select(sta, eff, chg) %>% 
    na.omit %>% 
    ungroup %>% 
    left_join(meddat, by = 'sta')

  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )

  out <- dat %>% 
    filter(sta %in% opts$sta)

  out <- list(
    toplo = out,
    opts = opts
  )

  return(out)
  
})

# text for optimal plot 1
opttxt <- reactive({
  
  # input
  powsel <- input$powsel
  smpsel <- input$smpsel
  optdat <- optdat()
  
  smpsel <- case_when(
    smpsel == 'D' ~ 'dry', 
    smpsel == 'S' ~ 'wet'
  )
  
  opts <- optdat$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  out <- paste0("Optimal sample effort in ", smpsel, " weather at ", powsel, " power: ", medv)
  
  return(out)
  
})

# optimal plot, by constituent
optplo <- reactive({

  # inputs
  optdat <- optdat()
  varthr <- varthr()
  powsel <- input$powsel

  # setup text labels in groups for plotly
  # sort out size vector for reldif if exists or not
  opts <- optdat$opts %>% 
    mutate(
      labs = paste0(sta, ', effort: ', round(eff, 2), ', change: ', round(chg, 2), ', median: ', medval, ', threshold: ', round(Threshold, 2), ', rel. diff: ', round(reldif, 2)
                    ),
      relsz = case_when(
        is.na(reldif) ~ 1,
        !is.na(reldif) ~ reldif
      )
    )
  
  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) + 
    geom_boxplot() +
    scale_y_continuous(limits = c(0.1, 2)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )

  # contour data
  toplo <- optdat$toplo

  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = sta), breaks = as.numeric(powsel), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = labs, size = relsz), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_size_continuous(guide = F, trans = 'reverse', limits = c(NA, 0)) + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1, height = 150, width = 900)
  pout2 <- ggplotly(p2, height = 450, width = 900, tooltip = 'group')
  
  out <- subplot(pout1, pout2, nrows = 2, heights = c(0.1, 0.9), shareX = T, titleY = T)
  return(out)
  
})

# optimal sample effort data, all constituents
optdat2 <- reactive({
  
  # input
  powsel2 <- input$powsel2
  consel2 <- input$consel2
  smpsel <- input$smpsel
  shdsel <- input$shdsel
  
  if(shdsel == 'all')
    shdsel <- unique(pows$Watershed)
  
  if(consel2 == 'organs')
    sels <- c('GLYP', 'Malathion')
  else 
    sels <- eval(parse(text = consel2)) 
   
  # rename methrsdat paramaters for join
  thrjn <- methrsdat %>% 
    rename(
      StationCode = sta, 
      Parameter = par
    )
  
  dat <- pows %>% 
    filter(par %in% !!sels) %>% 
    filter(wxt %in% smpsel) %>% 
    filter(Watershed %in% shdsel)

  # get medians by station, constituent
  # estimate relative difference from threshold if available
  meddat <- medat %>% 
    filter(Parameter %in% !!sels) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Parameter) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    left_join(thrjn, by = c('StationCode', 'Parameter')) %>% 
    mutate(
      thrdif = abs(medval - Threshold), 
      reldif = (thrdif / Threshold)
    ) %>% 
    rename(
      sta = StationCode, 
      par = Parameter
      )

  opts <- dat %>% 
    group_by(sta, par) %>% 
    nest %>% 
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel2))
    ) %>% 
    dplyr::select(-data) %>% 
    unnest(opt) %>% 
    dplyr::select(-opt) %>% 
    na.omit %>% 
    unite('stapar', sta, par, remove = F) %>% 
    ungroup %>% 
    left_join(meddat,by = c('sta', 'par'))

  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )
  
  out <- dat %>% 
    unite('stapar', sta, par, remove = F) %>% 
    filter(stapar %in% opts$stapar)

  selopteff <- opteff %>% 
    filter(powin %in% powsel2) %>% 
    filter(par %in% sels) %>% 
    filter(wxt %in% smpsel)
  
  out <- list(
    toplo = out,
    opts = opts, 
    selopteff = selopteff
  )
  
  return(out)
  
})

# text for optimal plot 2
opttxt2 <- reactive({
  
  # input
  powsel2 <- input$powsel2
  smpsel <- input$smpsel
  optdat2 <- optdat2()
  
  smpsel <- case_when(
    smpsel == 'D' ~ 'dry', 
    smpsel == 'S' ~ 'wet'
  )
  
  opts <- optdat2$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  out <- paste0("Optimal sample effort in ", smpsel, " weather at ", powsel2, " power: ", medv)
  
  return(out)
  
})

# optimal plot, all constituents
optplo2 <- reactive({
  
  # inputs
  optdat2 <- optdat2()
  powsel2 <- input$powsel2
  
  toplo <- optdat2$toplo
  opts <- optdat2$opts
  selopteff <- optdat2$selopteff

  # setup text labels in groups for plotly
  # sort out size vector for reldif if exists or not
  opts <- opts %>% 
    mutate(
      labs = paste0(sta, ', ', par, ' effort: ', round(eff, 2), ', change: ', round(chg, 2), ', median: ', medval, ', threshold: ', round(Threshold, 2), ', rel. diff: ', round(reldif, 2)
                    ),
      relsz = case_when(
        is.na(reldif) ~ max(.$reldif, na.rm = T),
        !is.na(reldif) ~ reldif
      )
    )

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) + 
    geom_boxplot() +
    scale_y_continuous(limits = c(0.1, 2)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )
  
  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = stapar), breaks = as.numeric(powsel2), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = labs, size = relsz), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    scale_size_continuous(guide = F, trans = reverselog_trans(10)) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1)#, height = 150, width = 900)
  pout2 <- ggplotly(p2, tooltip = 'group')#, height = 450, width = 900)
  
  pout3 <- plot_ly() %>% 
    add_trace(data = selopteff, y = ~par, x = ~eff, type = 'box', text = ~sta, boxpoints = 'all', jitter = 0.3, pointpos= 0, orientation = 'h') %>%
  layout(
    yaxis = list(title = ''), 
    xaxis = list(title= 'Optimal effort by site'), 
    showlegend = F
    )

  out <- subplot(pout3, pout1, pout2, nrows = 3, heights = c(0.45, 0.1, 0.45), shareX = T, titleY = T)
  return(out)
  
})

# tabular data for optimal effort for grouped constituents
opttab2 <- reactive({
  
  optdat2 <- optdat2()

  totab <- optdat2$opts %>% 
    select(par, sta, eff, medval, Threshold, thrdif)
  
  out <- reactable(totab, 
                   groupBy = 'par', 
                   columns = list(
                     par = colDef(name = 'Constituent'),
                     sta = colDef(name = 'Station'),
                     eff = colDef(name = 'Optimal effort'),
                     medval = colDef(name = 'Median value at station'),
                     thrdif = colDef(name = 'Diff. of median from threshold')
                   ),
                   defaultColDef = colDef(
                     footerStyle = list(fontWeight = "bold"),
                     format = colFormat(digits = 2, separators = TRUE),
                     resizable = TRUE
                     )
  )
  
  return(out)
  
})

# all trends across stations for selected constituent
alltrnd <- reactive({
  
  # input
  varsel3 <- input$varsel3
  
  req(varsel3)
  
  out <- medat %>%
    filter(Parameter %in% varsel3) %>%
    mutate(
      Year = year(Date),
      Month = month(Date, label = T)
    ) %>%
    group_by(StationCode, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(StationCode) %>%
    # filter(n() == 10) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){

        nval <- nrow(na.omit(x))
        knout <- try(kendallTrendTest(dev ~ Year, x), silent = T)
        outpval <- try(p_ast(knout$p.value), silent = T)
        
        if(!inherits(outpval, 'try-error')){
          
          outest <- round(knout$estimate, 2)
          out <- c(n = nval, outest, pval = outpval) %>%
            data.frame %>%
            t %>%
            data.frame %>%
            select(-intercept) %>% 
            mutate_if(is.factor, function(x) as.character(x))
          
        }
        
        if(inherits(outpval, 'try-error')){
          
          out <- data.frame(n = nval, tau = NA, slope = NA, pval = NA)
          
        }
 
        return(out)
        
      })
    ) %>%
    select(-data) 
  
  res <- do.call('rbind', out$res)
  out <- out %>% 
    select(-res) %>% 
    bind_cols(res) %>% 
    mutate(
      trend = ifelse(tau < 0, 'dec', 'inc'), 
      slope = as.numeric(slope),
      n = as.numeric(n),
      tau = as.numeric(tau)
    ) %>% 
    ungroup()

  return(out)
  
})

# table for all trends
alltrndtab <- reactive({
  
  # input
  alltrnd <- alltrnd()
  
  totab <- alltrnd
  
  HTML(knitr::kable(totab, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))

})

# map for all trends
alltrndmap <- reactive({

  # input
  alltrnd <- alltrnd()

  locs <- medat %>%
    select(StationCode, Longitude, Latitude) %>%
    unique

  tomap <- alltrnd %>%
    left_join(locs, by = 'StationCode') %>%
    na.omit %>% 
    st_as_sf(coords = c("Longitude", "Latitude"), crs = prj)

  # point colors
  cols <- tomap %>%
    mutate(
      cols = factor(trend, levels = c('dec', 'inc'), labels = c('lightgreen', 'tomato1')),
      cols = as.character(cols)
    ) %>%
    pull(cols)

  # size values
  cexv <- tomap %>%
    pull(tau) %>%
    abs %>%
    scales::rescale(to = c(2, 15))

   # hover pt labels
  labs <- paste(tomap$StationCode, ': ', tomap$trend, ', tau = ', tomap$tau, ', p = ', tomap$pval)
  mapviewOptions(leafletHeight = 500)

  out <- mapview(tomap, zcol = 'tau', cex = cexv, label = labs, col.regions = cols, legend = F, map.types = mptyps)@map

  return(out)

})
```

This website presents an evaluation of the Orange County mass emissions monitoring dataset. The content is separated into four main tabs.  

* __Inventory__: Map-based and tabular summaries of monitoring effort and basic characteristics of the data
* __Trends and power analyses__: Changes over time by select constituents and locations, including power analyses to help identify optimal sampling effort
* __Station differences__: A comparison of time series between stations to identify similarities among trends
* __Overall trends__: Map-based and tabular summary of trend tests for all stations shown together

Each main tab includes sub-tabs or drop-down menus for selecting and viewing different content. Most analyses are also grouped by constituent type as nutrients, metals, or organics.  The following shows which constituents are included in each type. 

* __Nutrients__: `r paste(nutrs, collapse = ', ')`
* __Metals__: `r paste(metals, collapse = ', ')`
* __Organics__: `r paste(organs, collapse = ', ')`

## Inventory {.tabset .tabset-pills}

### Maps

These three maps show the monitoring stations where mass emissions data are collected.  Each map shows different information, the first showing the watershed for each station, the second showing the number of parameters collected at each station (for the entire period of record), and the third showing the number of years for available data.  Each map is linked so that the mouse pointer is synced between the three.

```{r}
tomap <- medat %>% 
  select(StationCode, Watershed, Longitude, Latitude) %>% 
  unique %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m1a <- mapview(tomap, zcol = 'Watershed', layer.name = 'Watershed location', homebutton = F, map.types = mptyps)

tomap <- medat %>% 
  select(StationCode, Parameter, Longitude, Latitude) %>% 
  unique %>% 
  group_by(StationCode, Longitude, Latitude) %>% 
  summarise(n = n()) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m2a <- mapview(tomap, zcol = 'n', layer.name = 'Number of parameters', homebutton = F, col.regions = magma, map.types = mptyps)

tomap <- medat %>% 
  select(StationCode, yr = Date, Longitude, Latitude) %>% 
  mutate(yr = year(yr)) %>% 
  unique %>% 
  group_by(StationCode, Longitude, Latitude) %>% 
  summarise(n = n()) %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m3a <- mapview(tomap, zcol = 'n', layer.name = 'Number of years', homebutton = F, col.regions = magma, map.types = mptyps)

leafsync::sync(m1a, m2a, m3a, ncol = 1) 
```

### Tabular

These tables provide a more detailed summary of the data available at each station.  The drop-down menus can be used to select a constituent type (nutrients, metals, or organics) and the type of data shown in each table.  The data type can be selected as the total number of observations, the variance across observations, and the median absolute deviance (MAD) of observations for each station/constituent combination.  The MAD estimates provide a more robust estimate of variance when outliers are present or the data are highly skewed.  

```{r}
column(12, 
       column(4,
         selectInput('consel1', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs') 
       ),
       column(4, 
         selectInput('tabtyp', 'Table type:', choices = c('Number of observations', 'Variance', 'Median absolute deviation'))
       )
)
```

```{r}
renderUI(invtab())
```

## Trends and power analyses {.tabset .tabset-pills}

This tab shows trends and power analysis results for selected constituents. The drop-down menus are filters to select the data to observe. The constituent type filters which constituents can be selected.  The watershed filters the stations that can be selected.  Finally, the sampling weather selection filters dry weather or wet weather sampling for the selected station/constituent.  Each sub-tab contains additional information about the results.

```{r}
column(12, 
  column(6, 
       selectInput('consel2', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs')
  ),
  column(6, 
       selectInput('shdsel', 'Select watershed:', choices = c('all', unique(pows$Watershed)))
      )
  
)

column(12,
  column(6, 
       renderUI({
       
         req(input$varsel)
         
         # input
         varsel <- input$varsel
         shdsel <- input$shdsel
         
         if(shdsel == 'all')
           shdsel <- unique(pows$Watershed)
         
         sels <- medat %>% 
           filter(Parameter %in% varsel) %>% 
           filter(Watershed %in% shdsel) %>% 
           pull(StationCode) %>% 
           unique
         
         selectInput('stasel', 'Select station:', choices = sels)  
         
       })
  ),
  column(6, 
       renderUI({
       
         # input
         consel2 <- input$consel2
         
         sels <- eval(parse(text = consel2))
         selectInput('varsel', 'Select constituent:', choices = sels)
         
       })
  )
)

column(12, 
  column(6, 
       selectInput('smpsel', 'Select sampling weather:', choices = wx)
  )
)
```

### Observed

These plots show the observed time series for `r renderText(input$varsel)` at `r renderText(input$stasel)` during `r renderText(names(wx[which(unlist(wx) == input$smpsel)]))` sampling. The top plot is the raw data, the middle plot shows boxplots of the raw data grouped by year, and the bottom plot shows boxplots of the raw data grouped by month.  Points in red in the top plot are those that were at or below the detection limit for the constituent. 

```{r}
renderPlot({obsp1()}, height = 350, width = 700)
renderPlot({obsp2()}, height = 300, width = 700)
renderPlot({obsp3()}, height = 300, width = 700)
```

### Trends

This sub-tab shows the annual trends for `r renderText(input$varsel)` at `r renderText(input$stasel)` during `r renderText(names(wx[which(unlist(wx) == input$smpsel)]))` sampling.  The top plot shows trends for the time series after removing the overall mean. This is an effective approach for trend analysis by evaluating deviation of the annual averages relative to the grand mean. Bars in green show annual averages greater than the grand mean and bars in red show annual averages less than the grand mean.  The bars are centered on the zero line, which is a reference for the grand mean. The y-axis reports the grand mean of the constituent in parentheses. The trend is shown as the dotted line for a regression of the annual averages over time.  

```{r}
renderPlot({trndp1()}, height = 350, width = 900)
```

This table shows the regression results from the above plot.  Parameter estimates (Year and Intercept) are shown with their standard errors in parentheses.  

```{r, results='asis'}
renderUI({trndtab1()})
```

<br>

The plots below show the observed time series with measurements averaged to year/month (left) and a moving window average for a 12 month period with deviations around the average (right). The right plot is an alternative visualization for deviations around the long-term trend.

```{r}
renderPlot({trndp2()}, height = 350, width = 900)
```

<br>

Finally, Kendall tests provide an alternative indication of trend by evaluating magnitude, direction, and significance of a change over time. The test is a non-parametric equivalent to the regression analysis above. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

```{r, results = 'asis'}
renderUI({trndtab2()})
```

### Power analyses

This sub-tab shows the results for two different power analyses. Power is described as the likelihood of identifying a trend as statistically significant given the actual magnitude of the trend and sampling frequency.  __For all scenarios, sampling frequency is expressed as a proportion of the observed effort.__  Power is expected to decrease with decreasing trend magnitudes and decreasing sampling frequency.

The __first__ power analysis was conducted to estimate the ability to detect a specific trend for a desired sampling frequency.  This analysis used repeated sampling (n = 1000) of a simulated time series with similar characteristics as the data observed at station `r renderText(input$stasel)`. The observed time series for `r renderText({input$varsel})` at `r renderText({input$stasel})` is shown below.  

```{r}
renderPlot({powplo1()}, height = 350, width = 900)
```

Results for the power analyses is shown below. The x-axis shows relative sample effort as a proportion of the observed, varying from 10% of the observed (0.1) to twice that of the observed (2). The y-axis shows the magnitude of the actual simulated trend relative to the average concentration of `r renderText({input$varsel})` at `r renderText({input$stasel})`.  The trend magnitude varies as a 10% (0.1) to 100% (1) increase above the average at the site.  The isolines in the plot show lines of constant power for different magnitudes and sample effort.  As expected, power increases with larger trend magnitudes and decreases with less sampling effort. 

```{r}
renderPlot({powplo3()}, height =650, width = 900)
```

A __second__ power analysis was conducted to quantify the likelihood of observing an exceedance of a concentration for `r renderText(input$varsel)` at a given sample density.  This provides an indication of how likely you are to detect a concentration above a value of interest within your sampling design.  Similar methods as the first analysis were used such that power was estimated by repeated sampling of a simulated time series.  Rather than estimating significance of a trend at a simulated magnitude of change, power was defined as significance of a test to detect the mean value of the time series as being different from a specified threshold. Results are shown below, where the x-axis shows relative sample effort and the y-axis shows the concentration defining the threshold.  The interpretation of the power estimates are slightly different than the first analysis.  Rather than showing the percentage of time for which a trend would be detected, the power values show the probability that the true mean is equal to the concentration on the y-axis at a given level of sample effort.   

```{r}
renderPlot({powplo6()}, height = 650, width = 900)
```

### Optimal effort by constituent

This sub-tab summarizes results for the first power analysis across all stations for `r renderText({input$varsel})`.  The summaries provide an opportunity to identify optimal sample effort.  For all power curves for the constituent, a desired level of power is chosen (`r renderText({input$powsel})`).  All power curves are then plotted that meet the criteria of being monotonic across all levels of sample effort for which power was estimated (some were non-monotonic due to stochastic sub-sampling and/or insufficient data).   

The "optimal" level of sampling for each station is estimated as the point which the slope of y ~ x exceeds that of x ~ y, such that further reductions in sample effort (x) caused disproportionate increases in magnitude of the required trend (y) to detect for the desired power (`r renderText(input$powsel)`).  In other words, optimal was defined as the maximum reduction in sample effort where the increase in the magnitude of the trend change did not increase substantially relative to the reduction in sample effort.  __The gray points in the plot show the optimal level of effort for the station__.  The optimal level of effort for the constituent is then summarized across all stations on the top marginal boxplot, i.e., the median optimal value across all stations. 

Each grey point (optimal effort) is also sized in proportion to how close the median value of `r renderText({input$varsel})` is to the threshold.  Larger points indicate the median is close to the threshold, suggesting that changes in sample effort should be more carefully examined than stations where the median is farther from the threshold.  Thresholds were obtained from OCPW and are approximate in some cases where thresholds vary as a function of conditions measured ata site, e.g., water hardness for metals or pH/Temperature for Ammonia.  

```{r}
column(12, 
       column(4, selectInput('powsel', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

`r renderText(opttxt())`

```{r}
renderPlotly(optplo())
```

<br>
<br>
Note: Changing the station selection above does not affect the estimates since the optimal level is an aggregate across stations.  

### Optimal effort across constituents

This sub-tab further summarizes power across sites for all constituents of the selected type (`r renderText(input$consel2)`). This is the same plot as the previous tab, except power curves that satisfy the requirement for estimating optimal power are combined across constituents for the selected constituent type.  The top plot shows boxplot distributions of optimal power efforts for each station separated by constituent.  The middle (white) boxplot shows the distribution after combining optimal efforts across constituents.  The optimal effort is the median of all optimal efforts combined.  The bottom plot shows power curves for all stations and constituents with the grey points indicating the optimal effort at a station.  The grey points are sized relative to how close the median concentration at a site is to the threshold. Thresholds were obtained from OCPW and are approximate in some cases where thresholds vary as a function of conditions measured ata site, e.g., water hardness for metals or pH/Temperature for Ammonia.   

```{r}
column(12, 
       column(4, selectInput('powsel2', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

`r renderText(opttxt2())`

```{r}
output$optplo2 <- renderPlotly(optplo2())
plotlyOutput('optplo2', height = '700px')
```

<br>
<br>
Note: Changing the station and constituent selection above does not affect the estimates since the optimal level is an aggregate across stations and constituents for the selected constituent type.  

Tabular data below shows the same results from the plot. 

```{r}
output$opttab2 <- renderReactable(opttab2()) 
fillCol(
  reactableOutput('opttab2')
)
```

## Station differences {.tabset .tabset-pills}

This tab shows similarities among stations for selected constituents.  This information can be useful to identify which stations have similar water quality characteristics over time and which stations do not.  Sampling less frequently at stations with similar characteristics may be useful for optimizing efficiency of the monitoring program.  

```{r, fig.height = 5, fig.width = 6, fig.align = 'center'}
# rename some nutrient parameters
meprp <- medat %>% 
  filter(!StationCode %in% 'SICG03') %>% 
  mutate(
    Date = floor_date(Date, unit = 'month')
  ) %>% 
  filter(Parameter %in% c(metals, nutrs, organs)) %>% 
  select(Watershed, StationCode, Date, Parameter, Result) %>% 
  group_by(Watershed, StationCode, Date, Parameter) %>% 
  summarise(Result = mean(Result, na.rm = T)) %>% 
  group_by(StationCode, Parameter) %>% 
  mutate(Result = case_when(
    is.na(Result) ~ mean(Result, na.rm = T), 
    T ~ Result
    )
  ) %>% 
  ungroup() 

siteshd <- meprp %>% 
  select(Watershed, StationCode) %>% 
  unique
```

```{r}
column(12,
  column(6,
        selectInput('consel3', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'), selected = 'nutrs')
         ),
  column(6,
         renderUI({
           
           # input
           consel3 <- input$consel3
         
           if(consel3 == 'organs')
             sels <- c('GLYP', 'Malathion')
           else 
            sels <- eval(parse(text = consel3))
           
           selectInput('varsel2', 'Select constituent:', choices = sels)
           
         })
  )
)
column(12, 
  column(6, 
       selectInput('stasel2', 'Select first station:', choices = unique(pows$sta), selected = 'SDMF05')
  ), 
  column(6, 
       selectInput('stasel3', 'Select second station:', choices = unique(pows$sta), selected = 'SADF01')
  )
)
```

This plot shows a Principal Components Analysis (PCA) comparison of all sites, dates, and constituents and a dissimilarity matrix for `r renderText({input$varsel2})` between the time series at each station.  Blue tiles are more similar and red are more dissimilar.  The larger points (black and transparent black) in the PCA plot correspond to the observations at the two selected stations from the drop-down menus above.  The dissimilarity estimate for the two selected sites is also emphasized by black outline in the right plot. Sites with points that closely overlap on the PCA plot have lower dissimilarity measures (blue tiles), whereas sites with less overlap show higher dissimilarity measures (red tiles).  

```{r}
renderPlot({mulplo()}, height = 550, width = 900)
```

Information for the two selected stations above can be further evaluated by viewing the observed time series.  Sites that are similar will have time series with similar characteristics.  This will likely apply to the observed data, the boxplots by year, and the boxplots by month. 

### Time series

```{r}
renderPlot({obsp4()}, height = 450, width = 700)
```

### By year

```{r}
renderPlot({obsp5()}, height = 450, width = 700)
```

### By month

```{r}
renderPlot({obsp6()}, height = 450, width = 700)
```

## Overall trends

```{r}
column(12, 
  column(6, 
       selectInput('consel4', 'Select constituent type:', choices = list('Metals' =  'metals', 'Nutrients' = 'nutrs', 'Organic' = 'organs'),  selected = 'nutrs')
  ),
  column(6, 
       renderUI({
       
         # input
         consel4 <- input$consel4

         if(consel4 == 'organs')
             sels <- c('GLYP', 'Malathion')
           else 
            sels <- eval(parse(text = consel4))
           
         sels <- eval(parse(text = consel4))
         selectInput('varsel3', 'Select constituent:', choices = sels)
         
       })
  )
)

```

This final tab shows results of trends at all stations using Kendall tests. These tests provide a non-parametric indication of a trend by evaluating magnitude, direction, and significance of a change over time. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

The maps show the value for tau (direction of trend) for a Kendall test for changes across stations, green for decreasing and red for increasing. Size of the point is the magnitude of the estimated change over time.  The table shows the detailed results from the map.

```{r}
renderLeaflet(alltrndmap())
```

```{r}
renderUI(alltrndtab())
```
