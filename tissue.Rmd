---
output: 
    html_document:
        css: styles.css
runtime: shiny
---

# OC MS4 monitoring program, tissue samples {.tabset}


This website presents an evaluation of the Orange County tissue sampling dataset. The content is separated into four main tabs.  

* __Inventory__: Map-based and tabular summaries of monitoring effort and basic characteristics of the data
* __Trends and power analyses__: Changes over time by select constituents and locations, including power analyses to help identify optimal sampling effort
* __Station differences__: A comparison of time series between stations to identify similarities among trends
* __Overall trends__: Map-based and tabular summary of trend tests for all stations shown together

Each main tab includes sub-tabs or drop-down menus for selecting and viewing different content. For all analyses, multiple congeners for the same constituent were summed to create the total tissue concentration for DDT, PCB, and Chlordane.  Also, multiple samples taken during the same day were averaged in many cases. 

```{r setup, message = F, warning = F, results = 'hide', echo = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F, echo = F, fig.path = 'figs/', dev.args = list(family = 'serif'))

library(tidyverse)
library(sf)
library(mapview)
library(lubridate)
library(leaflet)
library(leafsync)
library(viridisLite)
library(lubridate)
library(gridExtra)
library(stargazer)
library(EnvStats)
library(shiny)
library(kableExtra)
library(mgcv)
library(metR)
library(vegan)
library(ggord)
library(patchwork)
library(ggrepel)
library(ggExtra)
library(plotly)
library(matrixStats)
library(reactable)
library(shinyWidgets)

mptyps <- c("CartoDB.Positron", "CartoDB.DarkMatter", "OpenStreetMap", "Esri.WorldImagery", "OpenTopoMap")

mapviewOptions(leafletHeight = 300)

prj <- 4326 # wgs84

source('R/funcs.R')

##
# ggplot themes

thm1 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    strip.text = element_text(hjust = 0),
    axis.title.x = element_blank(), 
    legend.title = element_blank(), 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm2 <- theme_bw(base_size = 16) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

thm3 <- theme_bw(base_size = 12) + 
  theme(
    strip.background = element_blank(), 
    strip.placement = 'outside', 
    legend.position = 'bottom', 
    panel.grid = element_blank()
  )

pbase <- theme_bw(base_family = 'serif') +
  theme(
    panel.grid.major = element_blank(), 
    panel.grid.minor = element_blank(), 
    axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1, size = 10), 
    axis.text.y = element_text(size = 10),
    legend.position = 'top',
    legend.direction = 'horizontal',
    # plot.margin = unit(c(4,4,0,0), "lines"),
    strip.background = element_blank(), 
    strip.text.y = element_text(angle = 0, hjust = 0, vjust = 0.5), 
    panel.background = element_rect(fill = 'black')
  ) 

data(tsdat)
data(tspows)
data(tsextpows)
data(tsthrs)
data(tsopteff)
data(tsopteffext)

# for conditional UI selections
tssel <- tsdat %>% 
  group_by(StationCode, Parameter, Type, Species) %>% 
  summarise(n = n())

# tops
# tops <- c('DDT', 'PCB', 'Se')
tops <- c('%Lipid', '%Solids', 'Total chlordane', 'Se', 'Hg', 'DDT', 'PCB', 'Toxaphene')
```

```{r reactives}
# inventory table
invtab1 <- reactive({
  
  # input
  tabtyp <- input$tabtyp
  typsel4 <- input$typsel4

  # filter by parameters
  sums <- tsdat %>% 
    filter(Type %in% typsel4)

  if(tabtyp == 'Number of observations'){
    
    sums <- sums %>% 
      dplyr::count(Parameter, StationCode) %>% 
      filter(Parameter %in% tops) %>%
      bind_rows(group_by(., Parameter) %>%
                summarise(n=sum(n)) %>%
                mutate(StationCode='Total')) %>%
      bind_rows(group_by(., StationCode) %>%
                summarise(n=sum(n)) %>%
                mutate(Parameter='Total')) %>%
      spread(Parameter, n, fill=0) %>% 
      select_at(c('StationCode', tops, 'Total'))
  
    alltot <- sums %>% 
      filter(StationCode != 'Total')
    coltot <- sums %>% 
      filter(StationCode == 'Total')
    
    totab <- bind_rows(alltot, coltot)
    
    cap <- 'Number of observations at each site'
  
  }
       
  if(tabtyp == 'Number of unique sample days'){
    
    sums <- sums %>% 
      select(Parameter, StationCode, Date) %>% 
      filter(Parameter %in% tops) %>% 
      unique %>% 
      dplyr::count(Parameter, StationCode) %>% 
      bind_rows(group_by(., Parameter) %>%
                summarise(n=sum(n)) %>%
                mutate(StationCode='Total')) %>%
      bind_rows(group_by(., StationCode) %>%
                summarise(n=sum(n)) %>%
                mutate(Parameter='Total')) %>%
      spread(Parameter, n, fill=0) %>% 
      select_at(c('StationCode', tops, 'Total'))
  
    alltot <- sums %>% 
      filter(StationCode != 'Total')
    coltot <- sums %>% 
      filter(StationCode == 'Total')
    
    totab <- bind_rows(alltot, coltot)
    
    cap <- 'Number of unique sample days at each site'
  
  }
  
  if(tabtyp == 'Variance'){
    
    totab <- sums %>% 
      filter(Parameter %in% tops) %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(vr = round(var(Result, na.rm = T), 2)) %>% 
      spread(Parameter, vr, fill = NA)
    
    cap <- 'Variance at each site'
    
  }
  
  if(tabtyp == 'Median absolute deviation'){
    
    totab <- sums %>% 
      filter(Parameter %in% tops) %>% 
      group_by(Parameter, StationCode) %>% 
      summarise(md = round(mad(Result, na.rm = T), 2)) %>% 
      spread(Parameter, md, fill = NA)
    
    cap <- 'Median absolute deviation at each site'
    
  }
  
  HTML(knitr::kable(totab, format = 'html', caption = cap) %>% 
      kable_styling(full_width = T, font_size = 14))  
    
})

# unique sample years table
invtab2 <- reactive({
  
  # inputs
  typsel4 <- input$typsel4
  
  sums <- tsdat %>%
    filter(Type %in% typsel4) %>% 
    mutate(Year = as.character(year(Date))) %>% 
    filter(Parameter %in% tops) %>% 
    select(StationCode, Parameter, Year) %>% 
    unique %>% 
    dplyr::count(StationCode, Parameter) %>% 
    spread(Parameter, n, fill = 0)
  
  HTML(knitr::kable(sums, format = 'html', caption = "Number of unique sample years at each site, by parameter") %>% 
    kable_styling(full_width = T, font_size = 14))  
  
})

# unique sample months
invtab3 <- reactive({
  
  # input
  typsel4 <- input$typsel4
  
  sums <- tsdat %>%
    filter(Type %in% typsel4) %>% 
    mutate(Month = as.character(month(Date))) %>% 
    filter(Parameter %in% tops) %>% 
    select(StationCode, Parameter, Month) %>% 
    unique %>% 
    dplyr::count(StationCode, Parameter) %>% 
    spread(Parameter, n, fill = 0)
  
  HTML(knitr::kable(sums, format = 'html', caption = "Number of unique sample months at each site, by parameter") %>% 
    kable_styling(full_width = T, font_size = 14))

})

# selected station, parameter data, values are median for unique days
stapardat <- reactive({

  # inputs
  stasel <- input$stasel
  varsel <- input$varsel
  typsel <- input$typsel
  sppsel <- input$sppsel
  
  req(sppsel)
 
  validate(
    need(length(sppsel) == 1, "Select one species to view results on this tab")
  )
  
  out <- tsdat %>%
    filter(Species %in% sppsel) %>% 
    filter(Type %in% typsel) %>% 
    filter(Parameter %in% varsel) %>%
    filter(StationCode %in% stasel) %>%
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection',
        T ~ 'within range'
      ),
      Detection = factor(Detection, levels = c('below detection', 'within range')),
      Year = year(Date),
      Month = month(Date, label = T)
    ) %>% 
    group_by(StationCode, Date, Parameter, Units, Detection, Year, Month) %>% 
    summarise(Result = median(Result, na.rm = T)) %>% 
    ungroup()

  validate(
    need(nrow(out) > 0, 'No data in selection')
  )

  return(out)

})

# first observed plot
obsp1 <- reactive({

  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)
  
  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Date, y = Result)) +
    geom_line() +
    geom_point(aes(colour = Detection)) +
    thm1 +
    scale_y_log10() +
    scale_colour_manual(values = c('tomato1', 'black'), drop = F) +
    labs(
      subtitle = paste0(stasel, ', ', typsel, ', ', sppsel),
      title = ttl,
      y = 'Concentration'
    )

  return(p)

})

# second observed plot
obsp2 <- reactive({

  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)

  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) +
    geom_boxplot() +
    thm1 +
    scale_y_log10() +
    # scale_colour_manual(values = c('tomato1', 'black')) +
    labs(
      subtitle = paste0(stasel, ', ', typsel, ', ', sppsel),
      title = paste(ttl, 'by year'),
      y = 'Concentration'
    )

  return(p)

})

# third observed plot
obsp3 <- reactive({

  # inputs
  stapardat <- stapardat()
  stasel <- input$stasel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)

  toplo <- stapardat
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) +
    geom_boxplot() +
    thm1 +
    scale_y_log10() +
    # scale_colour_manual(values = c('tomato1', 'black')) +
    labs(
      subtitle = paste0(stasel, ', ', typsel, ', ', sppsel),
      title = paste(ttl, 'by month'),
      y = 'Concentration'
    )

  return(p)

})

# trend data
trnddat <- reactive({

  # input
  stapardat <- stapardat()

  out <- try({stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    ungroup %>%
    mutate(
      avg = round(avg, 2),
      Parameter = paste0(Parameter, ' (', avg, ')')
    )
  })

  return(out)

})

# first trend plot
trndp1 <- reactive({

  # input
  trnddat <- trnddat()
  stasel <- input$stasel

  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )

  subttl <- paste0(stasel, ', average in parentheses on y-axis')

  p <- ggplot(trnddat, aes(x = Year, y = dev, fill = dev)) +
    geom_bar(stat = 'identity', colour = 'grey') +
    scale_fill_gradient2('Deviations from average (+/-)', low = 'tomato1', mid = 'grey90', high = 'lightgreen', midpoint = 0) +
    facet_wrap(~Parameter, strip.position = 'left', ncol = 1, scales = 'free_y') +
    thm1 +
    theme(axis.title.y = element_blank()) +
    geom_smooth(method = 'lm', se = F, linetype = 'dashed', color = 'black') +
    # scale_y_log10() +
    # scale_y_continuous('Density (fish/100ft)') +
    geom_hline(aes(yintercept = 0)) +
    labs(
      title = 'Deviation from annual averages by constituent',
      subtitle = subttl
    ) +
    guides(fill = guide_colourbar(barwidth = 15, barheight = 0.5))

  return(p)

})

# first trend table
trndtab1 <- reactive({

  # input
  trnddat <- trnddat()

  validate(
    need(!inherits(trnddat, 'try-error'), 'Insufficient data')
  )

  mods <- trnddat %>%
    group_by(Parameter) %>%
    nest %>%
    mutate(
      mod = purrr::map(data, function(x) lm(dev ~ Year, x))
    ) %>%
    ungroup %>%
    mutate(
      Parameter = gsub('\\s\\(.*\\)$', '', Parameter)
    )

  out <- stargazer(mods$mod, type = 'html',
            covariate.labels = c('Year', 'Intercept'),
            column.labels = mods$Parameter,
            omit.stat = c('adj.rsq', 'ser'),
            column.sep.width = '10pt',
            dep.var.labels.include = F,
            digits = 2
            ) %>%
    HTML()

  return(out)

})

# second trends table
trndtab2 <- reactive({

  # input
  stapardat <- stapardat()

  totabs1kn <- try({stapardat %>%
    group_by(Parameter, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(Parameter) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){

        knout <- kendallTrendTest(dev ~ Year, x)
        outest <- round(knout$estimate, 2)
        outpval <- p_ast(knout$p.value)
        nval <- nrow(na.omit(x))
        out <- c(n = nval, outest, pval = outpval) %>%
          data.frame %>%
          t %>%
          data.frame %>%
          select(-intercept)
        return(out)

      })

    ) %>%
    select(-data) %>%
    unnest(res)
  })
  
  validate(
    need(!inherits(totabs1kn, 'try-error'), 'Insufficient data')
  )

  out <- HTML(knitr::kable(totabs1kn, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))

  return(out)

})

# third power plot
powplo3 <- reactive({

  # input
  stasel <- input$stasel
  varsel <- input$varsel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)

  validate(
    need(length(sppsel) == 1, "Select one species to view results on this tab")
  )
  
  toplo <- tspows %>%
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) %>% 
    filter(par %in% varsel) %>%
    filter(sta %in% stasel) 

  validate(
    need(nrow(na.omit(toplo)) > 1, 'Insufficient data')
  )
  
  p <- ggplot(toplo, aes(x = eff, y = chg, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    # scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Magnitude of trend change (%) of ', varsel),
      title = paste0('Power estimates for ', stasel, ', ', typsel, ', ', sppsel),
      subtitle = 'Lines show power for varying sample effort and trend magnitude',
      x = 'Relative sample effort'
    )

  p

})

# fourth power plot
powplo4 <- reactive({

  # input
  stasel <- input$stasel
  varsel <- input$varsel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)

  validate(
    need(length(sppsel) == 1, "Select one species to view results on this tab")
  )
  
  toplo <- tsextpows %>%
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) %>% 
    filter(par %in% varsel) %>%
    filter(sta %in% stasel) 

  validate(
    need(nrow(na.omit(toplo)) > 1, 'Insufficient data')
  )
  
  p <- ggplot(toplo, aes(x = yrs, y = chg, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    # scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Magnitude of trend change (%) of ', varsel),
      title = paste0('Power estimates for ', stasel, ', ', typsel, ', ', sppsel),
      subtitle = 'Lines show power for varying sample effort and trend magnitude',
      x = 'Years from present'
    )

  p

})

# sixth power plot
powplo6 <- reactive({

  # input
  stasel <- input$stasel
  varsel <- input$varsel
  typsel <- input$typsel
  sppsel <- input$sppsel

  req(sppsel)

  validate(
    need(length(sppsel) == 1, "Select one species to view results on this tab")
  )
  
  toplo <- tsthrs %>%
    filter(Species %in% sppsel) %>% 
    filter(Type %in% typsel) %>% 
    filter(Parameter %in% varsel) %>%
    filter(StationCode %in% stasel)

  validate(
    need(nrow(na.omit(toplo)) > 1, 'Insufficient data')
  )
  
  p <- ggplot(toplo, aes(x = effs, y = vals, z = pow)) +
    # geom_tile() +
    geom_contour(aes(colour = stat(level))) +
    scale_colour_viridis_c('Power') +
    thm2 +
    theme(legend.position = 'none') +
    scale_x_continuous(limits = c(0, 1)) +
    # scale_y_continuous(limits = c(0, 1)) +
    geom_text_contour() +
    labs(
      y = paste0('Concentration of ', varsel),
      title = paste0('Power estimates for ', stasel, ', ', typsel, ', ', sppsel),
      subtitle = 'Lines show the likelihood that the true mean for the sample is above the threshold',
      x = 'Relative sample effort'
    )

  p

})

# comparison of time series for stations
stapardat2 <- reactive({

  # inputs
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2
  typsel2 <- input$typsel2
  sppsel2 <- input$sppsel2
  
  req(sppsel2)

  out <- tsdat %>%
    filter(StationCode %in% c(stasel2, stasel3)) %>%
    filter(Type %in% typsel2) %>% 
    filter(Species %in% sppsel2) %>% 
    mutate(
      Detection = case_when(
        Qualifier %in% '<' ~ 'below detection',
        T ~ 'within range'
      ),
      Year = year(Date),
      Month = month(Date, label = T),
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    ) %>%
    filter(Parameter %in% varsel2) %>% 
    group_by(StationCode, Date, Parameter, Units, Detection, Year, Month) %>% 
    summarise(Result = median(Result, na.rm = T)) %>% 
    ungroup()

  validate(
    need(nrow(out) > 1, 'Insufficient data')
  )
  
  return(out)

})

# fourth observed plot
obsp4 <- reactive({

  # inputs
  stapardat2 <- stapardat2()

  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Date, y = Result)) +
    geom_line() +
    geom_point(aes(colour = Detection)) +
    facet_wrap(~StationCode, ncol = 1) +
    thm1 +
    # scale_y_log10() +
    scale_colour_manual(values = c('tomato1', 'black')) +
    labs(
      title = ttl,
      y = 'Concentration'
    )

  return(p)

})

# fifth observed plot
obsp5 <- reactive({

  # inputs
  stapardat2 <- stapardat2()

  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = factor(Year), y = Result, group = Year)) +
    geom_boxplot() +
    facet_wrap(~StationCode, ncol = 1) +
    thm1 +
    # scale_y_log10() +
    # scale_colour_manual(values = c('tomato1', 'black')) +
    labs(
      title = paste(ttl, 'by year'),
      y = 'Concentration'
    )

  return(p)

})

# sixth observed plot
obsp6 <- reactive({

  # inputs
  stapardat2 <- stapardat2()

  toplo <- stapardat2
  ttl <- unique(toplo$Parameter)

  p <- ggplot(toplo, aes(x = Month, y = Result, group = Month)) +
    geom_boxplot() +
    facet_wrap(~StationCode, ncol = 1) +
    thm1 +
    # scale_y_log10() +
    # scale_colour_manual(values = c('tomato1', 'black')) +
    labs(
      title = paste(ttl, 'by month'),
      y = 'Concentration'
    )

  return(p)

})

# dissimilarity data
disdat <- reactive({

  # input
  varsel2 <- input$varsel2
  typsel2 <- input$typsel2
  sppsel2 <- input$sppsel2

  req(sppsel2)

  dissim <- try({tsprp %>%
    filter(Parameter %in% varsel2) %>%
    filter(Type %in% typsel2) %>% 
    filter(Species %in% sppsel2) %>% 
    select(-Parameter, -Type, -Species) %>%
    spread(StationCode, Result) %>%
    column_to_rownames('Date') %>%
    decostand(method = 'log', na.rm = T) %>%
    decostand(method= 'standardize', na.rm = T) %>%
    rownames_to_column('Date') %>%
    gather('StationCode', 'Result', -Date) %>%
    spread(Date, Result) %>%
    column_to_rownames('StationCode') %>%
    vegdist(method = 'euclidean', na.rm = T) %>%
    as.matrix %>%
    as.data.frame %>%
    rownames_to_column('StationCode') %>%
    gather('StationCode2', 'dist', -StationCode) %>%
    left_join(siteshd, by = 'StationCode') %>%
    arrange(dist) %>%
    mutate(
      dist = ifelse(StationCode == StationCode2, NA, dist)
    )})
  
  validate(
    need(!inherits(dissim, 'try-error'), 'Insufficient data')
  )

  return(dissim)

})

# dissimilarity data, all constituents
discondat <- reactive({

  # inputs
  typsel2 <- input$typsel2
  sppsel2 <- input$sppsel2

  req(sppsel2)

  dissim <- try({sprp %>%
    filter(Parameter %in% tops) %>%
    filter(Type %in% typsel2) %>% 
    filter(Species %in% sppsel2) %>% 
    select(-Type, -Species) %>% 
    group_by(Parameter) %>%
    nest() %>%
    mutate(
      dis = purrr::map(data, function(data){

        out <- data %>%
          spread(StationCode, Result) %>%
          column_to_rownames('Date') %>%
          decostand(method = 'log', na.rm = T) %>%
          decostand(method= 'standardize', na.rm = T) %>%
          rownames_to_column('Date') %>%
          gather('StationCode', 'Result', -Date) %>%
          spread(Date, Result) %>%
          column_to_rownames('StationCode') %>%
          vegdist(method = 'euclidean', na.rm = T) %>%
          as.matrix %>%
          as.data.frame %>%
          rownames_to_column('StationCode') %>%
          gather('StationCode2', 'dist', -StationCode) %>%
          left_join(siteshd, by = 'StationCode') %>%
          arrange(dist) %>%
          mutate(
            dist = ifelse(StationCode == StationCode2, NA, dist)
          )

        return(out)

      })
    ) %>%
    select(-data) %>%
    unnest(dis) %>%
    na.omit %>%
    group_by(Parameter, StationCode) %>%
    summarise(dist = mean(dist, na.rm = T)) %>%
    group_by(StationCode) %>%
    summarise(dist = mean(dist, na.rm = T))})

  validate(
    need(!inherits(dissim, 'try-error'), 'Insufficient data')
  )

  return(dissim)

})

# multivariate comparison plots
mulplo <- reactive({

  # input
  disdat <- disdat()
  stasel2 <- input$stasel2
  stasel3 <- input$stasel3
  varsel2 <- input$varsel2
  typsel2 <- input$typsel2
  sppsel2 <- input$sppsel2
  
  req(sppsel2)

  ##
  # PCA

  toord <- tsprp %>%
    filter(Parameter %in% tops) %>%
    filter(Type %in% typsel2) %>% 
    filter(Species %in% sppsel2) %>% 
    select(-Type, -Species) %>% 
    spread(Parameter, Result) %>%
    na.omit %>%
    unite('rwnm', StationCode, Date) %>%
    column_to_rownames('rwnm')

  toord <- toord %>%
    decostand(method = 'log', na.rm = T) %>%
    decostand(method= 'standardize', na.rm = T) %>%
    select(which(!is.na(apply(., 2, var))))

  ord <- toord %>%
    prcomp(scale. = T, center = T)

  # station subset
  vals <- ord$x %>%
    as.data.frame %>%
    rownames_to_column() %>%
    mutate(StationCode = gsub('^(.*)\\_.*$', '\\1', rowname)) %>%
    filter(StationCode %in% c(stasel2, stasel3)) %>%
    rename(
      one = PC1,
      two = PC2
    ) %>%
    mutate(
      StationCode = factor(StationCode, levels = c(stasel2, stasel3))
    )

  p1 <- ggord(ord, size = 1, alpha = 0.4, vec_ext = 5, coord_fix = F, parse = F) +
    scale_fill_viridis_d(guide_legend(ncol = 1)) +
    geom_point(data = vals, aes(alpha = StationCode), size = 3) +
    scale_alpha_manual(values = c(0.2, 0.8)) +
    theme(
      legend.position = 'top',
      legend.title = element_blank(),
      legend.box = 'vertical'
      )

  ##
  # dissimilarity data and plots
  outplo <- disdat %>%
    filter(StationCode %in% stasel2) %>%
    filter(StationCode2 %in% stasel3)

  # dissimilarity ranges
  disrng <- range(disdat$dist, na.rm = T)

  dismid <- disrng[1] + (disrng[2] - disrng[1]) / 2
  subttl <- paste0("Dissimilarity between ", stasel2, " and ", stasel3, " ", round(outplo$dist, 1))

  p2 <- ggplot(disdat) +
    geom_tile(aes(x = StationCode, y = StationCode2, fill = dist), colour = 'black') +
    geom_tile(data = outplo, aes(x = StationCode, y = StationCode2), fill = NA, colour = 'black', size = 2) +
    scale_x_discrete('', expand = c(0, 0)) +
    scale_y_discrete('', expand = c(0, 0)) +
    scale_fill_gradient2('Dissimilarity between stations', low = 'lightblue', mid = 'white', high = 'tomato1', midpoint = dismid, limits = disrng) +
    guides(fill = guide_colourbar(barheight = 0.5, barwidth = 10, label.theme = element_text(size = 11, angle = 0))) +
    labs(
      title = varsel2,
      subtitle = subttl
    ) +
    pbase

  p1 + p2 + plot_layout(ncol = 2)

})

# optimal sample effort data
optdat <- reactive({

  # input
  varsel <- input$varsel
  powsel <- input$powsel
  typsel <- input$typsel
  sppsel <- input$sppsel
  
  req(sppsel)

  dat <- tspows %>% 
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) %>% 
    filter(par %in% varsel) 

  # get weighting for optimal value
  # stations with median value closest to median are given highest weight
  # farther from median, weight decreases
  meddat <- tsdat %>% 
    filter(Species %in% sppsel) %>%
    filter(Type %in% typsel) %>%
    filter(Parameter %in% varsel) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Species, Type) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    mutate(
      qntval = ecdf(medval)(medval), 
      qntdif = abs(qntval - 0.5), 
      qntwgt = 1 - qntdif
    ) %>% 
    rename(
      sta = StationCode,
      spp = Species, 
      typ = Type
      )

  opts <- try({dat %>%
    group_by(sta, typ, spp) %>%
    nest %>%
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel))
    ) %>%
    dplyr::select(-data) %>%
    unnest(opt) %>%
    dplyr::select(sta, spp, typ, eff, chg) %>% 
    na.omit %>%
    ungroup %>% 
    left_join(meddat, by = c('sta', 'spp', 'typ'))
  })
  
  validate(
    need(!inherits(opts, 'try-error'), 'Insufficient data, try lower power or different constituent')
  )
  
  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )

  out <- dat %>%
    filter(sta %in% opts$sta)

  out <- list(
    toplo = out,
    opts = opts
  )

  return(out)

})

# text for optimal plot 1
opttxt <- reactive({

  # input
  powsel <- input$powsel
  optdat <- optdat()

  opts <- optdat$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  out <- paste0("The optimal sample effort at ", powsel, " power: ", medv , ' relative effort')

  return(out)

})

# optimal plot, by constituent
optplo <- reactive({

  # inputs
  optdat <- optdat()
  powsel <- input$powsel

  toplo <- optdat$toplo %>% 
    unite('statypspp', sta, typ, spp, sep = ', ')
  opts <- optdat$opts

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) +
    geom_boxplot() +
    scale_y_continuous(limits = c(0.1, 2)) +
    coord_flip() +
    theme_void() +
    theme(
      panel.border = element_blank(),
      panel.grid = element_blank()
    )

  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = statypspp), breaks = as.numeric(powsel), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = sta, size = qntwgt), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_size_continuous(guide = F) + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')

  pout1 <- ggplotly(p1, height = 150, width = 900)
  pout2 <- ggplotly(p2, height = 450, width = 900)

  out <- subplot(pout1, pout2, nrows = 2, heights = c(0.1, 0.9), shareX = T, titleY = T)
  return(out)

})

# optimal sample effort data, time since present
optextdat <- reactive({

  # input
  varsel <- input$varsel
  powsel <- input$powsel
  typsel <- input$typsel
  sppsel <- input$sppsel
  
  req(sppsel)

  dat <- tsextpows %>% 
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) %>% 
    filter(par %in% varsel) 

  # get weighting for optimal value
  # stations with median value closest to median are given highest weight
  # farther from median, weight decreases
  meddat <- tsdat %>% 
    filter(Species %in% sppsel) %>% 
    filter(Type %in% typsel) %>% 
    filter(Parameter %in% varsel) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Species, Type) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    mutate(
      qntval = ecdf(medval)(medval), 
      qntdif = abs(qntval - 0.5), 
      qntwgt = 1 - qntdif
    ) %>% 
    rename(
      sta = StationCode,
      typ = Type, 
      spp = Species
      )

  opts <- try({dat %>%
    group_by(sta, typ, spp) %>%
    rename(eff = yrs) %>%   
    nest %>%
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel))
    ) %>%
    dplyr::select(-data) %>%
    unnest(opt) %>%
    dplyr::select(sta, spp, typ, eff, chg) %>%
    rename(yrs = eff) %>% 
    na.omit %>%
    ungroup %>% 
    unite('statypspp', sta, typ, spp, remove = F, sep = ', ') %>%
    left_join(meddat, by = c('sta', 'typ', 'spp'))
  })
  
  validate(
    need(!inherits(opts, 'try-error'), 'Insufficient data, try lower power or different constituent')
  )
  
  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data')
  )

  out <- dat %>%
    unite('statypspp', sta, typ, spp, remove = F, sep = ', ') %>% 
    filter(statypspp %in% opts$statypspp)

  out <- list(
    toplo = out,
    opts = opts
  )

  return(out)

})

# text for optimal plot 1, time since present
optexttxt <- reactive({

  # input
  powsel <- input$powsel
  optextdat <- optextdat()

  opts <- optextdat$opts
  medv <- median(opts$yrs, na.rm = T) %>% round(2)
  out <- paste0("The optimal sample effort at ", powsel, " power: ", medv , ' years')

  return(out)

})

# optimal plot, by constituent, time since present
optextplo <- reactive({

  # inputs
  optextdat <- optextdat()
  powsel <- input$powsel

  toplo <- optextdat$toplo
  opts <- optextdat$opts

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = yrs)) +
    geom_boxplot() +
    scale_y_continuous(limits = c(5, 50)) +
    coord_flip() +
    theme_void() +
    theme(
      panel.border = element_blank(),
      panel.grid = element_blank()
    )

  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = yrs, y = chg, z = pow, group = statypspp), breaks = as.numeric(powsel), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = yrs, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = yrs, y = chg, size = qntwgt), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_size_continuous(guide = F) + 
    scale_x_continuous(limits = c(5, 50)) + 
    thm3 +
    labs(
      x = 'Years from present', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')

  pout1 <- ggplotly(p1, height = 150, width = 900)
  pout2 <- ggplotly(p2, height = 450, width = 900)

  out <- subplot(pout1, pout2, nrows = 2, heights = c(0.1, 0.9), shareX = T, titleY = T)
  return(out)

})

# optimal sample effort data, all constituents
optdat2 <- reactive({

  # input
  powsel2 <- input$powsel2
  typsel <- input$typsel
  sppsel <- input$sppsel
  
  req(sppsel)

  dat <- tspows %>% 
    filter(par %in% tops) %>% 
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) 

  # get weighting for optimal value
  # stations with median value closest to median are given highest weight
  # farther from median, weight decreases
  meddat <- tsdat %>% 
    filter(Species %in% sppsel) %>% 
    filter(Type %in% typsel) %>% 
    filter(Parameter %in% tops) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Parameter, Type, Species) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    group_by(Parameter) %>% 
    mutate(
      qntval = ecdf(medval)(medval), 
      qntdif = abs(qntval - 0.5), 
      qntwgt = 1 - qntdif
    ) %>%
    ungroup() %>% 
    rename(
      sta = StationCode, 
      par = Parameter, 
      typ = Type,
      spp = Species
      )
  
  opts <- try({tspows %>%
    filter(typ %in% typsel) %>% 
    filter(spp %in% sppsel) %>% 
    group_by(sta, par, typ, spp) %>%
    nest %>%
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel2))
    ) %>%
    dplyr::select(-data) %>%
    unnest(opt) %>%
    dplyr::select(-opt) %>%
    na.omit %>%
    unite('stapartypspp', sta, par, typ, spp, remove = F, sep = ', ') %>%
    ungroup %>% 
    left_join(meddat,by = c('sta', 'par', 'typ', 'spp'))

  })
  
  validate(
    need(!inherits(opts, 'try-error'), 'Insufficient data, try lower power')
  )
  
  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data, try lower power')
  )

  validate(
    need('eff' %in% names(opts), 'Insufficient data, try lower power')
  )

  out <- tspows %>%
    unite('stapartypspp', sta, par, typ, spp, remove = F, sep = ', ') %>%
    filter(stapartypspp %in% opts$stapartypspp) %>% 
    filter(typ %in% typsel) %>% 
    filter(spp %in% sppsel)

  selopteff <- tsopteff %>%
    filter(powin %in% powsel2) %>% 
    filter(typ %in% typsel) %>% 
    filter(spp %in% sppsel)
  
  out <- list(
    toplo = out,
    opts = opts,
    selopteff = selopteff
  )

  return(out)

})

# text for optimal plot 2
opttxt2 <- reactive({

  # input
  powsel2 <- input$powsel2
  optdat2 <- optdat2()

  opts <- optdat2$opts
  medv <- median(opts$eff, na.rm = T) %>% round(2)
  
  out <- paste0("The optimal sample effort at ", powsel2, " power: ", medv , ' relative effort')

  return(out)

})

# optimal plot, all constituents
optplo2 <- reactive({

  # inputs
  optdat2 <- optdat2()
  powsel2 <- input$powsel2
  
  toplo <- optdat2$toplo
  opts <- optdat2$opts
  selopteff <- optdat2$selopteff

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = eff)) + 
    geom_boxplot() +
    scale_y_continuous(limits = c(0.1, 2)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )
  
  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = eff, y = chg, z = pow, group = stapartypspp), breaks = as.numeric(powsel2), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = eff, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = eff, y = chg, group = stapartypspp, size = qntwgt), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_x_continuous(limits = c(0.1, 2)) + 
    scale_size_continuous(guide = F) + 
    thm3 +
    labs(
      x = 'Relative sample effort', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1)#, height = 150, width = 900)
  pout2 <- ggplotly(p2)#, height = 450, width = 900)
  
  pout3 <- plot_ly() %>% 
    add_trace(data = selopteff, y = ~par, x = ~eff, type = 'box', text = ~sta, boxpoints = 'all', jitter = 0.3, pointpos= 0, orientation = 'h') %>%
  layout(
    yaxis = list(title = ''), 
    xaxis = list(title= 'Optimal effort by site'), 
    showlegend = F
    )

  out <- subplot(pout3, pout1, pout2, nrows = 3, heights = c(0.35, 0.1, 0.55), shareX = T, titleY = T)
  return(out)
  
})

# optimal sample effort data, all constituents, time since present
optextdat2 <- reactive({

  # input
  powsel2 <- input$powsel2
  typsel <- input$typsel
  sppsel <- input$sppsel
  
  req(sppsel)

  dat <- tsextpows %>% 
    filter(par %in% tops) %>% 
    filter(spp %in% sppsel) %>% 
    filter(typ %in% typsel) 

  # get weighting for optimal value
  # stations with median value closest to median are given highest weight
  # farther from median, weight decreases
  meddat <- tsdat %>% 
    filter(Species %in% sppsel) %>% 
    filter(Type %in% typsel) %>% 
    filter(Parameter %in% tops) %>% 
    filter(StationCode %in% dat$sta) %>% 
    group_by(StationCode, Parameter, Type, Species) %>% 
    summarise(medval = median(Result, na.rm = T)) %>% 
    ungroup %>% 
    group_by(Parameter) %>% 
    mutate(
      qntval = ecdf(medval)(medval), 
      qntdif = abs(qntval - 0.5), 
      qntwgt = 1 - qntdif
    ) %>%
    ungroup() %>% 
    rename(
      sta = StationCode, 
      par = Parameter, 
      spp = Species, 
      typ = Type
      )
  
  opts <- try({tsextpows %>%
    filter(typ %in% typsel) %>% 
    filter(spp %in% sppsel) %>% 
    group_by(sta, par, typ, spp) %>%
    rename(eff = yrs) %>% 
    nest %>%
    mutate(
      opt = purrr::map(data, getopt, pow = as.numeric(powsel2))
    ) %>%
    dplyr::select(-data) %>%
    unnest(opt) %>%
    rename(yrs = eff) %>% 
    dplyr::select(-opt) %>%
    na.omit %>%
    unite('stapartypspp', sta, par, typ, spp, remove = F, sep = ', ') %>%
    ungroup %>% 
    left_join(meddat,by = c('sta', 'par', 'typ', 'spp'))
  })
  
  validate(
    need(!inherits(opts, 'try-error'), 'Insufficient data, try lower power')
  )
  
  # cut if no data
  validate(
    need(nrow(opts) > 0 & ncol(opts) > 1, 'Insufficient data, try lower power')
  )

  out <- tsextpows %>%
    unite('stapartypspp', sta, par, typ, spp, remove = F, sep = ', ') %>%
    filter(stapartypspp %in% opts$stapartypspp) 
  
  selopteff <- tsopteffext %>%
    filter(powin %in% powsel2) %>% 
    filter(typ %in% typsel) %>% 
    filter(spp %in% sppsel)
  
  out <- list(
    toplo = out,
    opts = opts,
    selopteff = selopteff
  )

  return(out)

})

# text for optimal plot 2, time since present
optexttxt2 <- reactive({

  # input
  powsel2 <- input$powsel2
  optextdat2 <- optextdat2()
  
  opts <- optextdat2$opts
  medv <- median(opts$yrs, na.rm = T) %>% round(2)
  
  out <- paste0("The optimal sample effort at ", powsel2, " power: ", medv , ' years')

  return(out)

})

# optimal plot, all constituents, time since present
optextplo2 <- reactive({

  # inputs
  optextdat2 <- optextdat2()
  powsel2 <- input$powsel2
  
  toplo <- optextdat2$toplo
  opts <- optextdat2$opts
  selopteff <- optextdat2$selopteff

  # boxplot
  p1 <- ggplot(opts, aes(x = 'x', y = yrs)) + 
    geom_boxplot() +
    scale_y_continuous(limits = c(5, 50)) + 
    coord_flip() + 
    theme_void() + 
    theme(
      panel.border = element_blank(), 
      panel.grid = element_blank()
    )
  
  # contours
  p2 <- ggplot(toplo) +
    geom_contour(aes(x = yrs, y = chg, z = pow, group = stapartypspp), breaks = as.numeric(powsel2), size = 0.5) + 
    # geom_text_repel(data = opts, aes(x = yrs, y = chg, label = sta)) +
    geom_point(data = opts, aes(x = yrs, y = chg, size = qntwgt, group = stapartypspp), pch = 21, fill = 'lightgrey', colour = 'black') + 
    scale_x_continuous(limits = c(5, 50)) + 
    scale_size_continuous(guide = F) + 
    thm3 +
    labs(
      x = 'Years from present', 
      y = paste0('Magnitude of trend change (%)')
    )

  # out <- p1 + p2 + plot_layout(ncol = 1, heights = c(0.1, 1))
  # pout <- ggMarginal(p1, type = 'boxplot', margins = 'x')
  
  pout1 <- ggplotly(p1)#, height = 150, width = 900)
  pout2 <- ggplotly(p2)#, height = 450, width = 900)
  
  pout3 <- plot_ly() %>% 
    add_trace(data = selopteff, y = ~par, x = ~yrs, type = 'box', text = ~sta, boxpoints = 'all', jitter = 0.3, pointpos= 0, orientation = 'h') %>%
  layout(
    yaxis = list(title = ''), 
    xaxis = list(title= 'Optimal time by site'), 
    showlegend = F
    )

  out <- subplot(pout3, pout1, pout2, nrows = 3, heights = c(0.35, 0.1, 0.55), shareX = T, titleY = T)
  return(out)
  
})

# all trends across stations for selected constituent
alltrnd <- reactive({
  
  # input
  varsel3 <- input$varsel3
  typsel3 <- input$typsel3
  sppsel3 <- input$sppsel3
  
  req(sppsel3)
  
  out <- tsdat %>%
    filter(Parameter %in% varsel3) %>%
    filter(Type %in% typsel3) %>% 
    filter(Species %in% sppsel3) %>% 
    mutate(
      Year = year(Date),
      Month = month(Date, label = T)
    ) %>%
    group_by(StationCode, Year) %>%
    summarise(
      Result = mean(Result, na.rm = T),
    ) %>%
    group_by(StationCode) %>%
    # filter(n() == 10) %>%
    mutate(
      avg = mean(Result, na.rm = T),
      dev = Result - avg
    ) %>%
    nest %>%
    mutate(
      res = purrr::map(data, function(x){

        nval <- nrow(na.omit(x))
        knout <- try(kendallTrendTest(dev ~ Year, x), silent = T)
        outpval <- try(p_ast(knout$p.value), silent = T)
        
        if(!inherits(outpval, 'try-error')){
          
          outest <- round(knout$estimate, 2)
          out <- c(n = nval, outest, pval = outpval) %>%
            data.frame %>%
            t %>%
            data.frame %>%
            select(-intercept) %>% 
            mutate_if(is.factor, function(x) as.character(x))
          
        }
        
        if(inherits(outpval, 'try-error')){
          
          out <- data.frame(n = nval, tau = NA, slope = NA, pval = NA)
          
        }
 
        return(out)
        
      })
    ) %>%
    select(-data) 
  
  res <- do.call('rbind', out$res)
  out <- out %>% 
    select(-res) %>% 
    bind_cols(res) %>% 
    mutate(
      trend = ifelse(tau < 0, 'dec', 'inc'), 
      slope = as.numeric(slope),
      n = as.numeric(n),
      tau = as.numeric(tau)
    ) %>% 
    ungroup()

  return(out)
  
})

# table for all trends
alltrndtab <- reactive({
  
  # input
  alltrnd <- alltrnd()
  
  totab <- alltrnd
  
  validate(
    need(nrow(na.omit(totab)) > 0, "Insufficient data")
  )

  HTML(knitr::kable(totab, format = 'html') %>%
    kable_styling(full_width = T, font_size = 14))

})

# map for all trends
alltrndmap <- reactive({

  # input
  alltrnd <- alltrnd()

  locs <- tsdat %>%
    select(StationCode, Longitude, Latitude) %>%
    unique

  tomap <- alltrnd %>%
    left_join(locs, by = 'StationCode') %>%
    na.omit %>% 
    st_as_sf(coords = c("Longitude", "Latitude"), crs = prj)

  validate(
    need(nrow(tomap) > 0, "Insufficient data")
  )
  
  # point colors
  cols <- tomap %>%
    mutate(
      cols = factor(trend, levels = c('dec', 'inc'), labels = c('lightgreen', 'tomato1')),
      cols = as.character(cols)
    ) %>%
    pull(cols)

  # size values
  cexv <- tomap %>%
    pull(tau) %>%
    abs %>%
    scales::rescale(to = c(2, 15))

   # hover pt labels
  labs <- paste(tomap$StationCode, ': ', tomap$trend, ', tau = ', tomap$tau, ', p = ', tomap$pval)
  mapviewOptions(leafletHeight = 500)

  out <- mapview(tomap, zcol = 'tau', cex = cexv, label = labs, col.regions = cols, legend = F, map.types = mptyps)@map

  return(out)

})
```

## Inventory {.tabset .tabset-pills}

### Maps

This map shows the monitoring stations where tissue sampling data are collected.  The points are colored by the number of years of monitoring at each station. For all stations, nine parameters were measured.

```{r, out.width = '100%'}
# tomap <- tsdat %>% 
#   select(StationCode, Parameter, Longitude, Latitude) %>% 
#   unique %>% 
#   filter(!is.na(Longitude)) %>% 
#   group_by(StationCode, Longitude, Latitude) %>% 
#   summarise(n = n()) %>% 
#   st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)
# 
# m1a <- mapview(tomap, zcol = 'n', layer.name = 'Number of parameters', homebutton = F, col.regions = magma, map.types = mptyps)

tomap <- tsdat %>% 
  select(StationCode, yr = Date, Longitude, Latitude) %>% 
  mutate(yr = year(yr)) %>% 
  unique %>% 
  filter(!is.na(Longitude)) %>% 
  group_by(StationCode, Longitude, Latitude) %>% 
  summarise(n = n()) %>% 
  ungroup() %>% 
  st_as_sf(coords = c('Longitude', 'Latitude'), crs = prj)

m2a <- mapview(tomap, zcol = 'n', layer.name = 'Number of years', homebutton = F, col.regions = magma, map.types = mptyps)

# leafsync::sync(m1a, m2a, ncol = 1) 

m2a
```

### Tabular

These tables report summary statistics for the raw data.  The top table shows the total number of observations, variance, or median absolute deviation (MAD) for all samples at each site.  The MAD estimates provide a more robust estimate of variance when outliers are present or the data are highly skewed. The top table is the only table that can be changed with the selection menu.  

The bottom two tables show the number of unique sample years and the number of unique sample months at each site for each parameter.  Multiple samples are often obtained during the same day which inflates the total sample size.  These two tables provide a better summary of seasonal and annual coverage for the monitoring program.

```{r}
column(12, 
  column(4, 
    selectInput('tabtyp', 'Table type:', choices = c('Number of observations', 'Number of unique sample days', 'Variance', 'Median absolute deviation'))
  ), 
  column(4,
    pickerInput('typsel4', label = 'Select tissue type:', choices = c("bird egg", "comp", "fillet", "remaining tissue"), selected = 'bird egg', options = list(`actions-box` = TRUE), multiple = TRUE)
  )
)
```

```{r}
renderUI(invtab1())
renderUI(invtab2())
renderUI(invtab3())
```

### Tabular, sample type summary

This table summarizes the number of tissue samples grouped by station code, parameter (constituent), tissue type (fillet, composite, bird egg, remaining), and species.  Expand the data for each station by clicking on the table.  The results are also filterable by typing in a value in the boxes just below the column names. __This table can help with selecting which data to show on the "Trends and power analyses" tab__.

```{r}
reactable(tssel, 
  groupBy = 'StationCode',
  defaultColDef = colDef(
    footerStyle = list(fontWeight = "bold"),
    format = colFormat(digits = 0, separators = TRUE),
    resizable = TRUE
    ),
  filterable = T
)
```

## Trends and power analyses {.tabset .tabset-pills}

This tab shows trends and power analysis results for selected constituents. The drop-down menus are filters to select the data to observe, one menu for constituent and another for the station.  Each sub-tab contains additional information about the results. For all analyses, __multiple samples per day were averaged__.

```{r}
column(12,
  column(6,

    selectInput('stasel', 'Select station:', choices = unique(tssel$StationCode))
         
  ),
  column(6,
  #   renderUI({
  #     
  #     # inputs
  #     stasel <- input$stasel
  #     
  #     req(stasel)
  #     
  #     tosel <- tssel %>% 
  #       filter(StationCode %in% stasel) %>% 
  #       pull(Parameter) %>% 
  #       unique()
  #     
  #     selpick <- ifelse('PCB' %in% tosel, 'PCB', tosel[1])
  #     
  #     selectInput('varsel', 'Select constituent:', choices = tosel, selected = selpick)
  #     
  #   })
  # )
  selectInput('varsel', 'Select constituent:', choices = tops, selected = 'PCB')
  )
)
column(12,
  column(6,
    # renderUI({
    #   
    #   # inputs
    #   stasel <- input$stasel
    #   varsel <- input$varsel
    #   
    #   req(varsel)
    #   
    #   tosel <- tssel %>% 
    #     filter(StationCode %in% stasel) %>% 
    #     filter(Parameter %in% varsel) %>% 
    #     pull(Type) %>% 
    #     unique()
    # 
    #   selectInput('typsel', 'Select tissue type:', choices = tosel)
    #   
    # })
    pickerInput('typsel', label = 'Select tissue type:', choices = c("bird egg", "comp", "fillet", "remaining tissue"), selected = 'bird egg', options = list(`actions-box` = TRUE), multiple = TRUE)
    
  ),
  column(6,
    renderUI({
      
      # inputs
      # stasel <- input$stasel
      # varsel <- input$varsel
      typsel <- input$typsel
      
      req(typsel)
      
      tosel <- tssel %>% 
        # filter(StationCode %in% stasel) %>% 
        # filter(Parameter %in% varsel) %>% 
        filter(Type %in% typsel) %>% 
        pull(Species) %>% 
        unique

      pickerInput(inputId = "sppsel", label = 'Select species:', choices = tosel,
        options = list(`actions-box` = TRUE), selected = tosel[1], multiple = TRUE)

    })
  )
)
```

### Observed

These plots show the observed time series for `r renderText(input$varsel)` at `r renderText(input$stasel)`. The top plot is the raw data, the middle plot shows boxplots of the raw data grouped by year, and the bottom plot shows boxplots of the raw data grouped by month.  Points in red in the top plot are those that were at or below the detection limit for `r renderText(input$varsel)`.

```{r}
renderPlot({obsp1()}, height = 350, width = 700)
renderPlot({obsp2()}, height = 300, width = 700)
renderPlot({obsp3()}, height = 300, width = 700)
```

### Trends

This sub-tab shows the annual trends for `r renderText(input$varsel)` at `r renderText(input$stasel)`.  The top plot shows trends for the time series after removing the overall mean. This is an effective approach for trend analysis by evaluating deviation of the annual averages relative to the grand mean. Bars in green show annual averages greater than the grand mean and bars in red show annual averages less than the grand mean.  The bars are centered on the zero line, which is a reference for the grand mean. The y-axis reports the grand mean of the constituent in parentheses. The trend is shown as the dotted line for a regression of the annual averages over time.  

```{r}
renderPlot({trndp1()}, height = 350, width = 900)
```

This table shows the regression results from the above plot.  Parameter estimates (Year and Intercept) are shown with their standard errors in parentheses. 

```{r, results='asis'}
renderUI({trndtab1()})
```

<br>

Finally, Kendall tests provide an alternative indication of trend by evaluating magnitude, direction, and significance of a change over time. The test is a non-parametric equivalent to the regression analysis above. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

```{r, results = 'asis'}
renderUI({trndtab2()})
```

### Power analyses

This sub-tab shows the results for two different power analyses. Power is described as the likelihood of identifying a trend as statistically significant given the actual magnitude of the trend and sampling frequency.  __For all scenarios, sampling frequency is expressed as a proportion of the observed effort, with sampling at 100% effort equal to site visits ~2x per year across the period of record.__  Power is expected to decrease with decreasing trend magnitudes and decreasing sampling frequency.

The __first__ power analysis was conducted to estimate the ability to detect a specific trend for a desired sampling frequency.  This analysis used repeated sampling (n = 1000) of a simulated time series with similar characteristics as the data observed at station `r renderText(input$stasel)`. The observed time series for `r renderText({input$varsel})` at `r renderText({input$stasel})` is shown below.

```{r}
renderPlot({obsp1()}, height = 350, width = 900)
```

Results for the power analyses are shown below. The x-axis shows relative sample effort as a proportion of the observed, varying from 10% of the observed (0.1) to twice that of the observed (2). The y-axis shows the magnitude of the actual simulated trend relative to the average concentration of `r renderText({input$varsel})` at `r renderText({input$stasel})`.  The trend magnitude varies as a 10% (0.1) to 100% (1) increase above the average at the site.  The isolines in the plot show lines of constant power for different magnitudes and sample effort.  As expected, power increases with larger trend magnitudes and decreases with less sampling effort.

```{r}
renderPlot({powplo3()}, height = 650, width = 900)
```

A __second__ power analysis was conducted that was similar to the first, except that power was evaluated relative to length of time at the observed level of sampling effort.  This analysis identifies the level of power at which a specified trend is observed relative to a specified period of time from the present.  In other words, how much time must pass before a certain trend is observed given the curent sampling effort? 

```{r}
renderPlot({powplo4()}, height = 650, width = 900)
```

A __third__ power analysis was conducted to quantify the likelihood of observing an exceedance of a concentration for `r renderText(input$varsel)` at a given sample density.  This provides an indication of how likely you are to detect a concentration above a value of interest within your sampling design.  Similar methods as the first analysis were used such that power was estimated by repeated sampling of a simulated time series.  Rather than estimating significance of a trend at a simulated magnitude of change, power was defined as significance of a test to detect the mean value of the time series as being different from a specified threshold. Results are shown below, where the x-axis shows relative sample effort and the y-axis shows the concentration defining the threshold.  The interpretation of the power estimates are slightly different than the first analysis.  Rather than showing the percentage of time for which a trend would be detected, the power values show the probability that the true mean is equal to the concentration on the y-axis at a given level of sample effort.

```{r}
renderPlot({powplo6()}, height = 650, width = 900)
```

### Optimal effort by constituent

This sub-tab summarizes results for the first and second power analysis across all stations for `r renderText({input$varsel})`.  The summaries provide an opportunity to identify optimal sample effort and optimal time to wait to observed a specified trend.  For all power curves for the constituent, a desired level of power is chosen (`r renderText({input$powsel})`).  All power curves are then plotted that meet the criteria of being monotonic across all levels of sample effort for which power was estimated (some were non-monotonic due to stochastic sub-sampling and/or insufficient data).  Note that changing the station selection above does not affect the estimates below since the optimal level is an aggregate across stations.

The "optimal" level of sampling for each station is estimated as the point which the slope of y ~ x exceeds that of x ~ y, such that further reductions in sample effort (x) caused disproportionate increases in magnitude of the required trend (y) to detect for the desired power (`r renderText(input$powsel)`).  In other words, optimal was defined as the maximum reduction in sample effort where the increase in the magnitude of the trend change did not increase substantially relative to the reduction in sample effort.  __The gray points in the plot show the optimal level of effort for the station__.  The optimal level of effort for the constituent is then summarized across all stations on the top marginal boxplot, i.e., the median optimal value across all stations.

Each grey point (optimal effort) is also sized in proportion to how close the median value of `r renderText({input$varsel})` is to the threshold.  Larger points indicate the median is close to the threshold, suggesting that changes in sample effort should be more carefully examined than stations where the median is farther from the threshold.

```{r}
column(12,
       column(4, selectInput('powsel', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

This plot shows power as a function of sample effort. `r renderText(opttxt())`

```{r}
renderPlotly(optplo())
```

<br>
<br>

This plot shows power as a function of time from present (years). `r renderText(optexttxt())`

```{r}
renderPlotly(optextplo())
```

<br>
<br>

### Optimal effort across constituents

This sub-tab further summarizes power for the first and second power analysis across sites for all constituents. These are the same plots as the previous tab, except power curves that satisfy the requirement for estimating optimal power are combined across constituents.  Each of the two plots includes subplots.  The top plot shows boxplot distributions of optimal power efforts for each station separated by constituent.  The middle (white) boxplot shows the distribution after combining optimal efforts across constituents.  The optimal effort is the median of all optimal efforts combined.  The bottom plot shows power curves for all stations and constituents with the grey points indicating the optimal effort at a station.  The grey points are sized relative to how close the median concentration at a site is to the threshold. Changing the station and constituent selection above does not affect the estimates since the optimal level is an aggregate across stations and constituents.


```{r}
column(12,
       column(4, selectInput('powsel2', 'Select power target:', choices = seq(0.1, 0.9, by = 0.1), selected = 0.8))
       )
```

<br>
<br>

This plot shows power as a function of sample effort. `r renderText(opttxt2())`

```{r}
output$optplo2 <- renderPlotly(optplo2())
plotlyOutput('optplo2', height = '700px')
```

<br>
<br>

This plot shows power as a function of time from present (years). `r renderText(optexttxt2())`

```{r}
output$optextplo2 <- renderPlotly(optextplo2())
plotlyOutput('optextplo2', height = '700px')
```

<br>
<br>

## Station differences {.tabset .tabset-pills}

This tab shows similarities among stations for selected constituents.  This information can be useful to identify which stations have similar tissue sample characteristics over time and which stations do not.  Sampling less frequently at stations with similar characteristics may be useful for optimizing efficiency of the monitoring program.

```{r, fig.height = 5, fig.width = 6, fig.align = 'center'}
# rename some nutrient parameters
tsprp <- tsdat %>%
  mutate(
    Date = floor_date(Date, unit = 'month')
  ) %>%
  filter(Parameter %in% tops) %>%
  select(StationCode, Type, Species, Date, Parameter, Result) %>%
  group_by(StationCode, Type, Species, Date, Parameter) %>%
  summarise(Result = mean(Result, na.rm = T)) %>%
  group_by(StationCode, Type, Species, Parameter) %>%
  mutate(Result = case_when(
    is.na(Result) ~ mean(Result, na.rm = T),
    T ~ Result
    )
  ) %>%
  ungroup()

siteshd <- tsprp %>%
  select(StationCode) %>%
  unique
```

```{r}
column(12,
  column(4,
    selectInput('varsel2', 'Select constituent:', choices = tops)
  ),
  column(4, 
    selectInput('typsel2', 'Select tissue type:', choices = c("bird egg", "comp", "fillet", "remaining tissue"))
  ),
  column(4,
    renderUI({
      
      # inputs
      typsel2 <- input$typsel2
      
      req(typsel2)
      
      tosel <- tssel %>% 
        filter(Type %in% typsel2) %>% 
        pull(Species) %>% 
        unique

      selectInput('sppsel2', 'Select species:', choices = tosel)
          
    })
  )
)
column(12,
  column(6,
    selectInput('stasel2', 'Select first station:', choices = unique(tspows$sta), selected = 'UNB')
  ),
  column(6,
    selectInput('stasel3', 'Select second station:', choices = unique(tspows$sta), selected = 'IRWD')
  )
)
```

This plot shows a Principal Components Analysis (PCA) comparison of all sites, dates, and constituents and a dissimilarity matrix for `r renderText({input$varsel2})` between the time series at each station.  Blue tiles are more similar and red are more dissimilar.  The larger points (black and transparent black) in the PCA plot correspond to the observations at the two selected stations from the drop-down menus above.  The dissimilarity estimate for the two selected sites is also emphasized by black outline in the right plot. Sites with points that closely overlap on the PCA plot have lower dissimilarity measures (blue tiles), whereas sites with less overlap show higher dissimilarity measures (red tiles).

```{r}
renderPlot({mulplo()}, height = 550, width = 900)
```

Information for the two selected stations above can be further evaluated by viewing the observed time series.  Sites that are similar will have time series with similar characteristics.  This will likely apply to the observed data, the boxplots by year, and the boxplots by month.

### Time series

```{r}
renderPlot({obsp4()}, height = 450, width = 700)
```

### By year

```{r}
renderPlot({obsp5()}, height = 450, width = 700)
```

### By month

```{r}
renderPlot({obsp6()}, height = 450, width = 700)
```

## Overall trends

```{r}
column(12,
  column(4,
    selectInput('varsel3', 'Select constituent:', choices = tops)
  ),
  column(4, 
    selectInput('typsel3', 'Select tissue type:', choices = c("bird egg", "comp", "fillet", "remaining tissue"))
  ),
  column(4,
    renderUI({
      
      # inputs
      typsel3 <- input$typsel3
      
      req(typsel3)
      
      tosel <- tssel %>% 
        filter(Type %in% typsel3) %>% 
        pull(Species) %>% 
        unique

      selectInput('sppsel3', 'Select species:', choices = tosel)
          
    })
  )
)
```

This final tab shows results of trends at all stations using Kendall tests. These tests provide a non-parametric indication of a trend by evaluating magnitude, direction, and significance of a change over time. The value for tau ranges from -1 to 1 and provides a measure of trend direction. The slope is the estimated change per year in density and the p-value shows the significance of the test.

The maps show the value for tau (direction of trend) for a Kendall test for changes across stations, green for decreasing and red for increasing. Size of the point is the magnitude of the estimated change over time.  The table shows the detailed results from the map.

```{r}
renderLeaflet(alltrndmap())
```

```{r}
renderUI(alltrndtab())
```